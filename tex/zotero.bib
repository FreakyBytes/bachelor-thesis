
@article{Scharm2016,
  title = {{{COMODI}}: An Ontology to Characterise Differences in Versions of Computational Models in Biology},
  volume = {7},
  issn = {2041-1480},
  shorttitle = {{{COMODI}}},
  doi = {10.1186/s13326-016-0080-2},
  language = {en},
  timestamp = {2016-08-20T18:35:51Z},
  number = {1},
  urldate = {2016-08-20},
  url = {http://jbiomedsem.biomedcentral.com/articles/10.1186/s13326-016-0080-2},
  journal = {Journal of Biomedical Semantics},
  author = {Scharm, Martin and Waltemath, Dagmar and Mendes, Pedro and Wolkenhauer, Olaf},
  month = dec,
  year = {2016},
  file = {COMODI\: An ontology to characterise differences in versions of computational models in biology - art%3A10.1186%2Fs13326-016-0080-2.pdf:/home/martin/.mozilla/firefox/2czweqll.default/zotero/storage/7RMWKU4C/art%3A10.1186%2Fs13326-016-0080-2.pdf:application/pdf}
}

@article{Mesirov2010,
  title = {{{COMPUTER SCIENCE}}. {{Accessible Reproducible Research}}},
  volume = {327},
  issn = {0036-8075},
  doi = {10.1126/science.1179653},
  abstract = {As use of computation in research grows, new tools are needed to expand
recording, reporting, and reproduction of methods and data.},
  timestamp = {2016-08-19T14:13:25Z},
  number = {5964},
  urldate = {2016-08-19},
  url = {http://www.ncbi.nlm.nih.gov/pmc/articles/PMC3878063/},
  journal = {Science (New York, N.Y.)},
  author = {Mesirov, Jill P.},
  month = jan,
  year = {2010},
  keywords = {Reproducibility},
  file = {PubMed Central Full Text PDF:/home/martin/.mozilla/firefox/2czweqll.default/zotero/storage/HCDHVPGX/Mesirov - 2010 - COMPUTER SCIENCE. Accessible Reproducible Research.pdf:application/pdf},
  pmid = {20093459},
  pmcid = {PMC3878063}
}

@inproceedings{Ebert1994,
  title = {A Declarative Approach to Graph Based Modeling},
  timestamp = {2016-08-19T11:48:52Z},
  booktitle = {Graph-{{Theoretic Concepts}} in {{Computer Science}}},
  publisher = {{Springer}},
  author = {Ebert, J{\"u}rgen and Franzke, Angelika},
  year = {1994},
  pages = {38--50},
  file = {Attachment:/home/martin/.mozilla/firefox/2czweqll.default/zotero/storage/VGM325TG/chp%3A10.1007%2F3-540-59071-4_36.pdf:application/pdf}
}

@article{Olivier2004,
  title = {Web-Based Kinetic Modelling Using {{JWS Online}}},
  volume = {20},
  timestamp = {2016-08-19T11:48:52Z},
  number = {13},
  journal = {Bioinformatics},
  author = {Olivier, Brett G and Snoep, Jacky L},
  year = {2004},
  pages = {2143--2144}
}

@article{Scharm2015a,
  title = {Extracting Reproducible Simulation Studies from Model Repositories Using the {{CombineArchive Toolkit}}},
  volume = {3},
  timestamp = {2016-08-19T11:48:52Z},
  journal = {PeerJ PrePrints},
  author = {Scharm, Martin and Waltemath, Dagmar},
  year = {2015},
  pages = {e792v1}
}

@article{Scharm2014,
  title = {The {{CombineArchive Toolkit}}-Facilitating the Transfer of Research Results},
  volume = {2},
  timestamp = {2016-08-19T11:48:52Z},
  journal = {PeerJ PrePrints},
  author = {Scharm, Martin and Wendland, Florian and Peters, Martin and Wolfien, Markus and Theile, Tom and Waltemath, Dagmar},
  year = {2014},
  pages = {e514v1}
}

@article{Waltemath2011,
  title = {Reproducible Computational Biology Experiments with {{SED}}-{{ML}}-the Simulation Experiment Description Markup Language},
  volume = {5},
  timestamp = {2016-08-19T11:48:53Z},
  number = {1},
  journal = {BMC systems biology},
  author = {Waltemath, Dagmar and Adams, Richard and Bergmann, Frank T and Hucka, Michael and Kolpakov, Fedor and Miller, Andrew K and Moraru, Ion I and Nickerson, David and Sahle, Sven and Snoep, Jacky L and {others}},
  year = {2011},
  pages = {1},
  file = {Waltemath et al. - 2011 - Reproducible computational biology experiments wit.pdf:/home/martin/.mozilla/firefox/2czweqll.default/zotero/storage/24ZG998W/Waltemath et al. - 2011 - Reproducible computational biology experiments wit.pdf:application/pdf}
}

@misc{Chemiker,
  title = {Organizing {{My Thoughts}}: {{Zotero Data Server Installation}}},
  shorttitle = {Organizing {{My Thoughts}}},
  timestamp = {2016-08-19T13:37:59Z},
  urldate = {2016-08-19},
  url = {http://signalverarbeitung.blogspot.com/2012/08/zotero-data-server-installation.html},
  author = {{Chemiker}},
  file = {Snapshot:/home/martin/.mozilla/firefox/2czweqll.default/zotero/storage/32ADHNT4/zotero-data-server-installation.html:text/html}
}

@article{Goble2010,
  title = {{{myExperiment}}: A Repository and Social Network for the Sharing of Bioinformatics Workflows},
  volume = {38},
  issn = {0305-1048, 1362-4962},
  shorttitle = {{{myExperiment}}},
  doi = {10.1093/nar/gkq429},
  abstract = {myExperiment (http://www.myexperiment.org) is an online research environment that supports the social sharing of bioinformatics workflows. These workflows are procedures consisting of a series of computational tasks using web services, which may be performed on data from its retrieval, integration and analysis, to the visualization of the results. As a public repository of workflows, myExperiment allows anybody to discover those that are relevant to their research, which can then be reused and repurposed to their specific requirements. Conversely, developers can submit their workflows to myExperiment and enable them to be shared in a secure manner. Since its release in 2007, myExperiment currently has over 3500 registered users and contains more than 1000 workflows. The social aspect to the sharing of these workflows is facilitated by registered users forming virtual communities bound together by a common interest or research project. Contributors of workflows can build their reputation within these communities by receiving feedback and credit from individuals who reuse their work. Further documentation about myExperiment including its REST web service is available from http://wiki.myexperiment.org. Feedback and requests for support can be sent to bugs\{at\}myexperiment.org.},
  language = {en},
  timestamp = {2016-08-19T14:03:42Z},
  number = {suppl 2},
  urldate = {2016-08-19},
  url = {http://nar.oxfordjournals.org/content/38/suppl_2/W677},
  journal = {Nucleic Acids Research},
  author = {Goble, Carole A. and Bhagat, Jiten and Aleksejevs, Sergejs and Cruickshank, Don and Michaelides, Danius and Newman, David and Borkum, Mark and Bechhofer, Sean and Roos, Marco and Li, Peter and Roure, David De},
  month = jan,
  year = {2010},
  keywords = {Reproducibility},
  pages = {W677--W682},
  file = {Full Text PDF:/home/martin/.mozilla/firefox/2czweqll.default/zotero/storage/SPA3D32B/Goble et al. - 2010 - myExperiment a repository and social network for .pdf:application/pdf;Snapshot:/home/martin/.mozilla/firefox/2czweqll.default/zotero/storage/8UBEJW4W/W677.html:text/html},
  pmid = {20501605}
}

@article{Hucka2015,
  title = {Promoting Coordinated Development of Community-Based Information Standards for Modeling in Biology: The {{COMBINE}} Initiative},
  volume = {3},
  timestamp = {2016-08-19T11:48:52Z},
  journal = {Frontiers in bioengineering and biotechnology},
  author = {Hucka, Michael and Nickerson, David P and Bader, Gary D and Bergmann, Frank T and Cooper, Jonathan and Demir, Emek and Garny, Alan and Golebiewski, Martin and Myers, Chris J and Schreiber, Falk and {others}},
  year = {2015},
  pages = {19},
  file = {Attachment:/home/martin/.mozilla/firefox/2czweqll.default/zotero/storage/CVI3DEGI/fbioe-03-00019.pdf:application/pdf}
}

@article{Scharm2015,
  title = {An Algorithm to Detect and Communicate the Differences in Computational Models Describing Biological Systems},
  timestamp = {2016-08-19T11:48:52Z},
  journal = {Bioinformatics},
  author = {Scharm, Martin and Wolkenhauer, Olaf and Waltemath, Dagmar},
  year = {2015},
  pages = {btv484},
  annote = {Extracted Annotations (8/19/2016, 3:23:40 PM)
"steadily increasing number of computational models are available from open repositories" (Scharm et al 2015:1)
"repositories provide the infrastructure necessary to maintain model code and associated metadata" (Scharm et al 2015:1)
"distribution of models through these repositories accelerates collaborative research and encourages model reuse" (Scharm et al 2015:1)
"Tracking the evolution of a model, that is providing information about changes in the model and its encoding, plays an important role in supporting the user" (Scharm et al 2015:1)
"The need of model version control has been emphasized repeatedly on several occasions (Li et al., 2010; Miller et al., 2011; Saffrey and Orton, 2009; Waltemath et al., 2013a)" (Scharm et al 2015:1)
"relation between versions of a model from different releases can be considered the history of the model's encoding" (Scharm et al 2015:2)
"In the simplest case, the history follows a single line along the time axis. In practice, however, models are subject to modifications, including corrections, extension and other refinements" (Scharm et al 2015:2)
"during model development, several alternatives are tested, leading to different paths in the history of a mode" (Scharm et al 2015:2)
"especially when branches with different modifications shall be merged back into a single version of the model at a later time" (Scharm et al 2015:2)
"For this reason, difference detection plays a key role in model version control" (Scharm et al 2015:2)
"We refer to model provenance as the field of research that investigates the nature of differences in model versions, seeking answers to the seven W-questions: Who, What, Where, Why, When, Which, With (How)?" (Scharm et al 2015:2)
"novel algorithm for difference detection in models of biological systems" (Scharm et al 2015:2)
"pre-processes the model documents, maps the hierarchical model structures and post-processes the resulting mappings" (Scharm et al 2015:2)
"mapping can then be exported in both machine and human readable formats" (Scharm et al 2015:2)
"algorithm is implemented in a software library called BiVeS" (Scharm et al 2015:2)
"It distinguishes six major steps:" (Scharm et al 2015:2)
"Pre-processing the XML documents" (Scharm et al 2015:2)
"Mapping the hierarchical structures" (Scharm et al 2015:2)
"Post-processing the resulting mapping" (Scharm et al 2015:2)
"Based on the identified mapping, the algorithm computes a delta" (Scharm et al 2015:2)
"delta can be converted" (Scharm et al 2015:2)
"two versions of an XML-encoded model are translated into an internal tree structure. For every node n in the tree, a hash sum n r and a weight n x are calculated" (Scharm et al 2015:2)
"The weight of a node is thus always greater than the weight of its children. As such, the weight represents the size of the corresponding subtree" (Scharm et al 2015:2)
"The hash sum of a node n represents the signature of the subtree rooted at n" (Scharm et al 2015:2)
"While n r unambiguously defines the subtree rooted in n, n r does not need to be unique among all nodes in the tree. Thus, if n r \textonequarter{} m r then the subtrees in n and m are identically equal" (Scharm et al 2015:2)
"First, nodes are being mapped with respect to their identifiers" (Scharm et al 2015:2)
"id attributes in the XML documents serve as identifiers. In addition, we also evaluate biological identifiers, specifically links into bio-ontologies" (Scharm et al 2015:2)
"Second, the initial mapping is propagated upwards into the trees." (Scharm et al 2015:3)
"The connections of a node's children are evaluated in a depth-first traversal of T 2 . If a node n in T 2 is connected to a node m in T 1 then a mapping of parent\dh{}n\TH{} to parent\dh{}m\TH{} is suggested" (Scharm et al 2015:3)
"If, in contrast, n is not connected, we examine the candidates that were previously suggested by the connections of n's children." (Scharm et al 2015:3)
"andidates which have a different tag name than n and candidates which already have a connection are neglected." (Scharm et al 2015:3)
"Among the remaining candidates, the algorithm chooses the one that received the best suggestions and connects it to n" (Scharm et al 2015:3)
"Third, the algorithm makes use of the initially computed signatures and maps nodes of T 2 on nodes of T 1" (Scharm et al 2015:3)
"A priority queueU is maintained to sort the nodes of T 2 based on their weights. Initially,U only consists of the root node of T 2 ." (Scharm et al 2015:3)
"UnlessU is empty, the algorithm repeatedly removes node n2U T 2 with the biggest weight, which represents the biggest subtree in the queue" (Scharm et al 2015:3)
"Fourth, the algorithm improves the quality of the mapping by examining the network structure of T 1 and T 2 in a top-down approach. For every mapping n2 T 2 on m2 T 1 , it compares unmatched children of n and m to find missed mappings" (Scharm et al 2015:3)
"The algorithm evaluates the matrix greedily and adds new mappings up to a maximum distance of 0.9. Thus, nodes which have nothing in common will not be connected" (Scharm et al 2015:3)
"Additional mapping rules capture the domain characteristics of the processed data. Following the current specifications for SBML and CellML, we prohibit certain changes in the hierarchical tree of document nodes. Specifically, we treat parts of the model as atomic constructs for which we define restrictions on possible network operations" (Scharm et al 2015:3)
"This step is a major reason why our algorithm outperforms standard XML diff algorithms." (Scharm et al 2015:3)
"insert if an entity is present in T 2 but absent in T" (Scharm et al 2015:3)
"delete if an entity is present in T 1 but absent in T" (Scharm et al 2015:3)
"move if a node is present in both documents, but either (i) the parents in the corresponding trees are not connected or (ii) the parents are connected, but the sequence of their siblings has changed" (Scharm et al 2015:3)
"update if the value of an attribute, a text node's content or the tag name of a node was modified" (Scharm et al 2015:3)
"After the mapping, we distinguish two types of nodes: mapped nodes and unmapped nodes. Unmapped nodes n2 T 1 [ T 2 are nodes for which the algorithm could not find a matching node in the opposite tree. These nodes and their attributes correspond to either inserts or deletes, depending on their origin" (Scharm et al 2015:3)
"In contrast, mapped nodes are nodes for which the algorithm did find a matching node in the opposite tree. If the parents of such a mapping of n2 T 2 onto m2 T 1 are not connected, or if the sequence among their siblings has changed, then these nodes are included in the set of moves" (Scharm et al 2015:3)
"Models are continuously modified. Consequently, new versions of a model are regularly being generated" (Scharm et al 2015:4)
"We observe three major steps in model development that result in new versions" (Scharm et al 2015:4)
"during the design phase" (Scharm et al 2015:4)
"during curation and error correction" (Scharm et al 2015:4)
"with updates of the format specification" (Scharm et al 2015:4)
"BiVeS detects the differences between model versions" (Scharm et al 2015:4)
"BiVeS communicates the differences" (Scharm et al 2015:4)
"Reproducibility of model-based scientific results has gained increasing attention" (Scharm et al 2015:5)
"Indeed, the ability to reproduce results is a basic requirement for the advance of science" (Scharm et al 2015:5)
"comparability of models and their versions. Model provenance and version control enable the widespread use and application of models, saving time and efforts during development" (Scharm et al 2015:7)
 However, the reuse of models requires the accessibility and comparability of models and their versions. Model provenance andversion control enable the widespread use and application of mod-els, saving time and efforts during development (note on p.7)
~
"Support for version control, however, is still limited." (Scharm et al 2015:7)
"Such a combined system stores model versions and detects the differences between them. In addition, it offers support for understanding these changes and filtering them according to the users' preferences, as discussed in the following." (Scharm et al 2015:7)
"Its major advantages over existing solutions for biological models are as follows: (i) it recognizes the models' hierarchical structures; (ii) it ignores white spaces, such as indentation, which generally do not affect the model's behaviour and (iii) it ignores the specific order of attributes in an entity. Additional post-processing rules capture the domain characteristics of the processed data and increase the significance of produced deltas. Currently, these rules are static" (Scharm et al 2015:7)
"BiVeS helps grasping the changes" (Scharm et al 2015:7)
"We are currently working on refining these filters using an ontology for differences. We envision that this ontology, together with tools for semi-automatic annotation, will help reduce the number of displayed changes to the ones that are meaningful or requested by the user" (Scharm et al 2015:7)
"Current limitations with respect to output formats are missing support for the SBGN format and suitable graphical representations of models that do not specify a reaction network" (Scharm et al 2015:7)
"Improving the reuse of computational models through version control" (Scharm et al 2015:8)},
  file = {Attachment:/home/martin/.mozilla/firefox/2czweqll.default/zotero/storage/ZXCMJSDU/Bioinformatics-2016-Scharm-563-70.pdf:application/pdf}
}

@article{Stanford2015,
  title = {The Evolution of Standards and Data Management Practices in Systems Biology},
  volume = {11},
  timestamp = {2016-08-19T11:48:53Z},
  number = {12},
  journal = {Molecular systems biology},
  author = {Stanford, Natalie J and Wolstencroft, Katherine and Golebiewski, Martin and Kania, Renate and Juty, Nick and Tomlinson, Christopher and Owen, Stuart and Butcher, Sarah and Hermjakob, Henning and Le Nov{\`e}re, Nicolas and {others}},
  year = {2015}
}

@incollection{DeVirgilio2014,
  title = {Model-Driven Design of Graph Databases},
  timestamp = {2016-08-19T11:48:52Z},
  booktitle = {Conceptual {{Modeling}}},
  publisher = {{Springer}},
  author = {De Virgilio, Roberto and Maccioni, Antonio and Torlone, Riccardo},
  year = {2014},
  pages = {172--185},
  file = {Attachment:/home/martin/.mozilla/firefox/2czweqll.default/zotero/storage/P47JUIS7/er12014.pdf:application/pdf}
}

@article{Waltemath2013,
  title = {Improving the Reuse of Computational Models through Version Control},
  volume = {29},
  issn = {1367-4803, 1460-2059},
  doi = {10.1093/bioinformatics/btt018},
  abstract = {Motivation: Only models that are accessible to researchers can be reused. As computational models evolve over time, a number of different but related versions of a model exist. Consequently, tools are required to manage not only well-curated models but also their associated versions.
Results: In this work, we discuss conceptual requirements for model version control. Focusing on XML formats such as Systems Biology Markup Language and CellML, we present methods for the identification and explanation of differences and for the justification of changes between model versions. In consequence, researchers can reflect on these changes, which in turn have considerable value for the development of new models. The implementation of model version control will therefore foster the exploration of published models and increase their reusability.
Availability: We have implemented the proposed methods in a software library called Biochemical Model Version Control System. It is freely available at http://sems.uni-rostock.de/bives/. Biochemical Model Version Control System is also integrated in the online application BudHat, which is available for testing at http://sems.uni-rostock.de/budhat/ (The version described in this publication is available from http://budhat-demo.sems.uni-rostock.de/).
Contact: dagmar.waltemath\{at\}uni-rostock.de},
  language = {en},
  timestamp = {2016-08-20T11:01:12Z},
  number = {6},
  urldate = {2016-08-20},
  url = {http://bioinformatics.oxfordjournals.org/content/29/6/742},
  journal = {Bioinformatics},
  author = {Waltemath, Dagmar and Henkel, Ron and H{\"a}lke, Robert and Scharm, Martin and Wolkenhauer, Olaf},
  month = mar,
  year = {2013},
  pages = {742--748},
  file = {Full Text PDF:/home/martin/.mozilla/firefox/2czweqll.default/zotero/storage/IQ9WXT2E/Waltemath et al. - 2013 - Improving the reuse of computational models throug.pdf:application/pdf;Snapshot:/home/martin/.mozilla/firefox/2czweqll.default/zotero/storage/UJAC873H/742.html:text/html},
  pmid = {23335018}
}

@inproceedings{Kohn2008,
  title = {{{SED}}-{{ML}}\textendash{}an {{XML}} Format for the Implementation of the {{MIASE}} Guidelines},
  timestamp = {2016-08-19T11:48:52Z},
  booktitle = {Computational {{Methods}} in {{Systems Biology}}},
  publisher = {{Springer}},
  author = {K{\"o}hn, Dagmar and Le Novere, Nicolas},
  year = {2008},
  pages = {176--190},
  annote = {Extracted Annotations (8/19/2016, 3:23:16 PM)"The need to build on existing studies by reusing models therefore becomes more imperative." (K{\"o}hn and Le Novere 2008:176)"that one needs to be able to exchange the biochemical and mathematical structure of models" (K{\"o}hn and Le Novere 2008:176)""the model, when instantiated within a suitable simulation environment, must be able to reproduce all relevant results given in the reference description that can readily" (K{\"o}hn and Le Novere 2008:176)"be simulated" [1]" (K{\"o}hn and Le Novere 2008:177)"MIRIAM does not impose to list those relevant results, or to describe how to obtain them." (K{\"o}hn and Le Novere 2008:177)"description of simulation experiments was mandatory to correctly exchange, re-use and interpret models" (K{\"o}hn and Le Novere 2008:177)"development of the Minimum Information About a Simulation Experiment (MIASE)" (K{\"o}hn and Le Novere 2008:177)"Information about the models simulated" (K{\"o}hn and Le Novere 2008:177)"explicitly define all models used in a simulation" (K{\"o}hn and Le Novere 2008:177)"changes that have to be applied to the model before the simulation" (K{\"o}hn and Le Novere 2008:177)"Information about the simulation methods used" (K{\"o}hn and Le Novere 2008:177)"simulation procedures to be ru" (K{\"o}hn and Le Novere 2008:177)"simulation algorithms used to perform them" (K{\"o}hn and Le Novere 2008:177)"Information about the tasks performed" (K{\"o}hn and Le Novere 2008:177)"describing how a simulation procedure has to be applied to a specific model, and in which order" (K{\"o}hn and Le Novere 2008:177)"Information about the outputs produced" (K{\"o}hn and Le Novere 2008:177)"often necessary to define the transformations that have to be performed on the raw output" (K{\"o}hn and Le Novere 2008:177)"how to provide the final results" (K{\"o}hn and Le Novere 2008:177)"The object model (SEDOM) presented in this paper is a platform independent prototype model encoding MIASE guidelines for simple simulation experiments." (K{\"o}hn and Le Novere 2008:177)"simulation is typically characterized by the simulation algorithm used, the settings applied to the simulation algorithm, and the simulation type" (K{\"o}hn and Le Novere 2008:180)"Using terms from an ontology rather than agreed-upon strings allows for reasoning. The simplest reasoning procedure is to find that algorithm available from KiSAO which is the closest to the one described in the simulation description, if the latter is not available for the user" (K{\"o}hn and Le Novere 2008:181)"The proposed solution is to extend the CellML meta data concept by additional simulation description concepts" (K{\"o}hn and Le Novere 2008:187)"With help of the CellML Metadata Specification, one or more simulation runs can be associated and described in one model specification. The description covers information about the type of simulation and about the simulation algorithm used" (K{\"o}hn and Le Novere 2008:187)"Unlike SED-ML, the approach chosen by the CellML community will store simulation specification details inside the model definition and thus be restricted to the use of CellML models" (K{\"o}hn and Le Novere 2008:187)"By suggesting to refer to a model rather than being part of it, SED-ML enhances reusability of simulation descriptions and supports the description of simulation experiments using not only a single model, but a number of models - which could even be encoded in different description formats" (K{\"o}hn and Le Novere 2008:187)"Additionally, the inclusion of simulation results is proposed. This is not considered to be part of SED-ML, but in our opinion should be covered by other efforts" (K{\"o}hn and Le Novere 2008:187)"SED-ML can encode simulation experiments being run with several models, which can even exist in different formats" (K{\"o}hn and Le Novere 2008:188)"SED-ML can specify different simulation settings applicable to the same model" (K{\"o}hn and Le Novere 2008:188)"Combinations of both are also possible, it is easily conceivable to set up a simulation experiment that results in an output comparing a parameter of a CellML model to a parameter of an SBML model, depending on different simulation algorithms" (K{\"o}hn and Le Novere 2008:188)"the output of variables from different simulation settings in one plot is only possible as long as all participating simulations produce the same time points" (K{\"o}hn and Le Novere 2008:188)"Another complex task that is not yet supported is the linear execution of simulation experiments, meaning that the result of one simulation is used as the input for another simulation task" (K{\"o}hn and Le Novere 2008:188)},
  file = {Attachment:/home/martin/.mozilla/firefox/2czweqll.default/zotero/storage/RITE2526/2008Koehn-Springer Reproducible computational biology experiments with SED-ML-the simulation experiment description markup language.pdf:application/pdf}
}

@article{Chen1976,
  title = {The {{Entity}}-{{Relationship Model}}\textendash{}{{Toward}} a {{Unified View}} of {{Data}}},
  volume = {Vol. 1, No. 1},
  timestamp = {2016-08-19T11:48:52Z},
  journal = {ACM Transactions on Database Systems},
  author = {Chen, Peter Pin-Shan},
  year = {1976},
  file = {Attachment:/home/martin/.mozilla/firefox/2czweqll.default/zotero/storage/XH5T9FXQ/p9-chen.pdf:application/pdf}
}

@inproceedings{Henkel2014,
  title = {{{MaSyMoS}}: {{Finding Hidden Treasures}} in {{Model Repositories}}.},
  timestamp = {2016-08-19T11:48:52Z},
  booktitle = {{{SWAT4LS}}},
  publisher = {{Citeseer}},
  author = {Henkel, Ron and Waltemath, Dagmar},
  year = {2014},
  file = {Attachment:/home/martin/.mozilla/firefox/2czweqll.default/zotero/storage/9JMCGF2V/10.1.1.663.4565.pdf:application/pdf}
}

@article{Waltemath2011a,
  title = {Simulation Experiment Description Markup Language ({{SED}}-{{ML}}): Level 1 Version 1},
  timestamp = {2016-08-19T11:48:53Z},
  journal = {Nature Precedings},
  author = {Waltemath, Dagmar and Bergmann, Frank T and Adams, Richard and Le Novere, Nicolas},
  year = {2011}
}

@article{Angles2008,
  title = {Survey of Graph Database Models},
  volume = {40},
  timestamp = {2016-08-19T11:48:51Z},
  number = {1},
  journal = {ACM Computing Surveys (CSUR)},
  author = {Angles, Renzo and Gutierrez, Claudio},
  year = {2008},
  pages = {1},
  annote = {Extracted Annotations (8/19/2016, 3:23:43 PM)"collection of data structure types" (Angles and Gutierrez 2008:2)"conceptual tools that make up a db-model should at least address data structuring, description, maintenance" (Angles and Gutierrez 2008:2)"a set of data structure types, a set of operators or inference rules, and a set of integrity rules [Codd 1980]" (Angles and Gutierrez 2008:2)},
  file = {Attachment:/home/martin/.mozilla/firefox/2czweqll.default/zotero/storage/6AQWEWW9/a1-angles.pdf:application/pdf}
}

@misc{zotero-null-25,
  title = {Dataserver - {{Modified}} Zotero Dataserver for Local Installations},
  timestamp = {2016-08-19T13:37:39Z},
  urldate = {2016-08-19},
  url = {http://git.27o.de/dataserver/about/},
  file = {dataserver - Modified zotero dataserver for local installations:/home/martin/.mozilla/firefox/2czweqll.default/zotero/storage/XHWVFZ6E/about.html:text/html}
}

@inproceedings{Cobena2002,
  title = {Detecting Changes in {{XML}} Documents},
  doi = {10.1109/ICDE.2002.994696},
  abstract = {We present a diff algorithm for XML data. This work is motivated by the support for change control in the context of the Xyleme project that is investigating dynamic warehouses capable of storing massive volumes of XML data. Because of the context, our algorithm has to be very efficient in terms of speed and memory space even at the cost of some loss of quality. Also, it considers, besides insertions, deletions and updates (standard in diffs), a move operation on subtrees that is essential in the context of XML. Intuitively, our diff algorithm uses signatures to match (large) subtrees that were left unchanged between the old and new versions. Such exact matchings are then possibly propagated to ancestors and descendants to obtain more matchings. It also uses XML specific information such as ID attributes. We provide a performance analysis of the algorithm. We show that it runs in average in linear time vs. quadratic time for previous algorithms. We present experiments on synthetic data that confirm the analysis. Since this problem is NP-hard, the linear time is obtained by trading some quality. We present experiments (again on synthetic data) that show that the output of our algorithm is reasonably close to the optimal in terms of quality. Finally we present experiments on a small sample of XML pages found on the Web},
  timestamp = {2016-08-19T14:51:27Z},
  booktitle = {18th {{International Conference}} on {{Data Engineering}}, 2002. {{Proceedings}}},
  author = {Cobena, G. and Abiteboul, S. and Marian, A.},
  year = {2002},
  keywords = {Change detection algorithms,Costs,Crawlers,Database languages,data warehouses,deletions,diff algorithm,experiments,HTML,hypermedia markup languages,ID attributes,information resources,insertions,linear time,move operation,NP hard,performance analysis,quadratic time,software performance evaluation,Subscriptions,subtrees,tree data structures,updates,Web and internet services,World Wide Web,XML,XML documents,XyDiff,Xyleme project},
  pages = {41--52},
  file = {IEEE Xplore Full Text PDF:/home/martin/.mozilla/firefox/2czweqll.default/zotero/storage/2FQFWGR7/Cobena et al. - 2002 - Detecting changes in XML documents.pdf:application/pdf;IEEE Xplore Abstract Record:/home/martin/.mozilla/firefox/2czweqll.default/zotero/storage/WACE4GT2/abs_all.html:text/html}
}

@article{McEntyre2015,
  title = {The {{BioStudies}} Database},
  volume = {11},
  timestamp = {2016-08-19T11:48:52Z},
  number = {12},
  journal = {Molecular systems biology},
  author = {McEntyre, Jo and Sarkans, Ugis and Brazma, Alvis},
  year = {2015},
  pages = {847}
}

@book{Hunt1976,
  title = {An Algorithm for Differential File Comparison},
  timestamp = {2016-08-20T18:28:09Z},
  urldate = {2016-08-20},
  url = {http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.278.6540\&rep=rep1\&type=pdf},
  publisher = {{Citeseer}},
  author = {Hunt, James Wayne and MacIlroy, M. D.},
  year = {1976},
  file = {[PDF] psu.edu:/home/martin/.mozilla/firefox/2czweqll.default/zotero/storage/99SK2A78/Hunt and MacIlroy - 1976 - An algorithm for differential file comparison.pdf:application/pdf}
}

@misc{Siriwaradhana2014,
  title = {From the Entity-Relationship to the Property-Graph Model},
  timestamp = {2016-08-20T18:39:50Z},
  urldate = {2016-08-20},
  url = {http://lambdazen.blogspot.com/2014/01/from-entity-relationship-to-property.html},
  author = {Siriwaradhana, Shalin},
  month = jan,
  year = {2014},
  file = {Snapshot:/home/martin/.mozilla/firefox/2czweqll.default/zotero/storage/SQCBWMFQ/from-entity-relationship-to-property.html:text/html}
}

@article{Henkel2015,
  title = {Combining Computational Models, Semantic Annotations and Simulation Experiments in a Graph Database},
  volume = {2015},
  timestamp = {2016-08-19T11:48:52Z},
  journal = {Database},
  author = {Henkel, Ron and Wolkenhauer, Olaf and Waltemath, Dagmar},
  year = {2015},
  pages = {bau130},
  annote = {Extracted Annotations (8/19/2016, 3:23:06 PM)"curation has a positive effect on the quality of models" (Henkel et al 2015:2)"Errors in the models' encoding are more likely to be detected" (Henkel et al 2015:2)"can be resolved and documented" (Henkel et al 2015:2)"models are distributed in standard formats" (Henkel et al 2015:2)"Semantic annotations relate model entities to external resources describing the underlying biology" (Henkel et al 2015:2)"Models could easily be kept in file systems and meta-data in relational data tables (1)." (Henkel et al 2015:2)"This storage concept has become unsuitable, because today's models contain heterogeneous meta-data." (Henkel et al 2015:2)"MIRIAM-compliant annotations cannot be mapped efficiently onto relational tables" (Henkel et al 2015:2)"heterogeneous structure and content" (Henkel et al 2015:2)"do not comply with the homogenous and pre-defined properties of relational tables." (Henkel et al 2015:2)"Meta-data that are in principle available, but not retrievable include the structure of the model (16), model versions (17) and simulation setups (18)." (Henkel et al 2015:2)"propose the concept of graph databases for model storage and retrieval" (Henkel et al 2015:2)"enable a flexible integration of model-related meta-data" (Henkel et al 2015:2)"key feature of our work is the explicit linking of data." (Henkel et al 2015:2)"A graph database for simulation models and associated data" (Henkel et al 2015:2)"novel storage concept that tightly links model code with modelrelated data" (Henkel et al 2015:2)"If models encode networks\textemdash{}why do we not store them as graphs" (Henkel et al 2015:3)"Many models in public databases encode networks that can be represented as graphs" (Henkel et al 2015:3)"No unified schema exists for models and meta-data, making it difficult to define a relational database schema" (Henkel et al 2015:3)"highly linked models, model entities and meta-data are difficult to represent in a table-based relational database" (Henkel et al 2015:3)"focus has shifted from model code to 'model-related data'" (Henkel et al 2015:3)"relational databases were developed for homogeneous, structured data, e.g. numerical data" (Henkel et al 2015:3)"Models, however, take various size and structure" (Henkel et al 2015:3)"Designing a relational representation for these links and keeping the database efficient at the same time are impossible" (Henkel et al 2015:3)"Semi-structured documents, however, have only loose constraints on the data structure (20), which cannot be handled efficiently by relational databases (21)" (Henkel et al 2015:3)"We chose the graph database Neo4J (25)" (Henkel et al 2015:3)"represents data in terms of nodes, edges and attributes" (Henkel et al 2015:3)"Nodes are connected via directed edges (relations) of certain types. Both nodes and edges can then hold attributes" (Henkel et al 2015:3)"follows the fundamental properties of databases, i.e. the ACID principles" (Henkel et al 2015:3)"Knupfer et al. (7) distinguish data for the extrinsic and intrinsic description of model function, behavior and structure" (Henkel et al 2015:3)"focus on the data requested by" (Henkel et al 2015:3)"MIRIAM" (Henkel et al 2015:3)"MIASE" (Henkel et al 2015:3)"Simulation descriptions" (Henkel et al 2015:4)"The ability to represent increasingly complex biological phenomena requires models to be instantiated using different initial conditions and parameters, and these conditions must be formally described together with the model itself" (Henkel et al 2015:4)"Semantic annotations and cross-references" (Henkel et al 2015:4)"Database design and data import" (Henkel et al 2015:4)"document root node is created for each data item" (Henkel et al 2015:4)"entry point for each ontology is a so-called ontology root node" (Henkel et al 2015:4)"SBML models (Figure 1, left) are represented by a model node" (Henkel et al 2015:4)"Attached to the model node are annotation nodes, including the reference publication" (Henkel et al 2015:4)"model node is also connected to reaction, species and compartment nodes to reflect the underlying structures" (Henkel et al 2015:4)"edge between the species node pM (a complex of phosphorylated Cyclin and phosphorylated cdc2) and the compartment node Cell represents the fact that the species pM is located in the compartment Cell" (Henkel et al 2015:4)"qualifiers in the SBML model (13, 34) allow us to incorporate further information on the type of relation between an entity and an ontology concept" (Henkel et al 2015:4)"for each global parameter a node is created and attached to the model node" (Henkel et al 2015:4)"same procedure holds for functions" (Henkel et al 2015:4)"unit declarations are currently omitted" (Henkel et al 2015:4)"semantic annotations are extracted from the SBML model and stored" (Henkel et al 2015:4)"representing some model entity are linked to nodes representing a particular term in a bio-ontology" (Henkel et al 2015:4)"Taken together, the sum of extracted information provides a detailed representation of the models' network structure and all annotations" (Henkel et al 2015:5)"CellML models" (Henkel et al 2015:5)"connections between so-called components" (Henkel et al 2015:5)"component contains variables and mathematical relationships that manipulate those variables" (Henkel et al 2015:5)"Examples for CellML components are physical compartments, events, species or other convenient modeling abstractions" (Henkel et al 2015:5)"entry point is a document node" (Henkel et al 2015:5)"connected to a model node" (Henkel et al 2015:5)"Attached to the model node are the component nodes" (Henkel et al 2015:5)"Each component holds a number of variables" (Henkel et al 2015:5)"variables are mapped to corresponding variables of connected components" (Henkel et al 2015:5)"model node links to the identical publication node as the SBML model" (Henkel et al 2015:5)"annotations are extracted from the CellML model and mapped to the database using the same URI scheme as with SBML models" (Henkel et al 2015:5)"SED-ML descriptions" (Henkel et al 2015:5)"SEDML node serves as the anchor for an experiment" (Henkel et al 2015:5)"Modelreference node links the experiment to all Model nodes used in the simulation" (Henkel et al 2015:5)"Algorithms used for simulation are described by concepts from the Kinetic Simulation Algorithm Ontology (KiSAO)" (Henkel et al 2015:5)"incorporate the concepts of frequently used bioontologies to be able to query the information hidden in the semantic annotations of in model representations and simulation descriptions" (Henkel et al 2015:5)"We parse these ontologies and add all concepts and relations as nodes and edges, respectively." (Henkel et al 2015:7)"Crossreferences between concepts of different ontologies are currently not mapped to the database" (Henkel et al 2015:7)"Table 1 summarizes the data types, number and size of the documents in our database" (Henkel et al 2015:7)"Linking model-related data" (Henkel et al 2015:7)"The main advantage of the previously described concept is its possibility to define flexible links between the data domains" (Henkel et al 2015:7)"links between annotations (in SBML, CellML and SED-ML) and ontology concepts" (Henkel et al 2015:7)"links between models (in SBML or CellML format) and SED-ML" (Henkel et al 2015:7)"links between model entities and SED-ML variables" (Henkel et al 2015:7)"links between model entities from different model representation formats" (Henkel et al 2015:7)"For each annotation in a model we add an explicit link to the data entry in the referenced bio-ontology" (Henkel et al 2015:7)"link is that between a model and a simulation description" (Henkel et al 2015:7)"do not store the specific processing of a model entity" (Henkel et al 2015:7)"we keep the information if a model entity is part of a simulation" (Henkel et al 2015:7)"DataGenerator nodes with model entities (c) when a SED-ML file is imported" (Henkel et al 2015:7)"links (a)-(c) can be inferred from information encoded in the models" (Henkel et al 2015:7)"regard them explicit links" (Henkel et al 2015:7)"In addition, we determine implicit links between models of different representation formats" (Henkel et al 2015:7)"If two models share a publication, the systems can infer implicit links between those entities that are equally named" (Henkel et al 2015:7)"The confidence can be increased further if the entities' annotations match" (Henkel et al 2015:7)"Discussion" (Henkel et al 2015:8)"The main advantages of a graph-based concept for model storage are easy integration of heterogeneous resources, extensibility with further data resources and improved model search." (Henkel et al 2015:8)"In a graph database, the integration of heterogeneous resources is straight forward" (Henkel et al 2015:8)"helpful for later model comparison are edges that connect nodes across model representation formats" (Henkel et al 2015:8)"allows modelers to quickly retrieve all models associated with a simulation experiment, and 'vice versa'" (Henkel et al 2015:8)"Our graph database is schema optional. Thus, new data resources can efficiently be integrated and the database easily be extended" (Henkel et al 2015:8)"offer further exciting applications, including the structure-based comparison of models" (Henkel et al 2015:8)"Once specific algorithms to map sub-models and identify suitable interfaces for automatized model coupling are in place, it will be possible to integrate them with our ranked retrieval system" (Henkel et al 2015:8)"Exploiting links to associated virtual experiments" (Henkel et al 2015:8)"retrieval system must also incorporate information about, and links to, simulation experiments" (Henkel et al 2015:9)"links between SED-ML elements and KiSAO allow us to define restrictions on the SED-ML files we want to consider in a search result" (Henkel et al 2015:9)"SED-ML descriptions may be defined as templates for virtual experiments" (Henkel et al 2015:9)"Virtual experiments are in silico assays of a model's behavioral repertoire, both in declaring what a model should do and verifying what it actually does (40). Such simulation descriptions are per definition applicable to classes of models, enabling the clustering of models by type of experiment that they reproduce correctly" (Henkel et al 2015:9)"To our knowledge this is the first time a system can answer queries spanned over different data sets and combining them with an index look-up" (Henkel et al 2015:9)"Statistics" (Henkel et al 2015:9)"Our graph database can also provide interesting statistics about models" (Henkel et al 2015:9)"most frequently used annotation in BioModels Database" (Henkel et al 2015:9)"the average number of annotations per model, as well as the minimum, maximum and the standard derivation" (Henkel et al 2015:9)"Comparison with other approaches" (Henkel et al 2015:10)"BioModels Database" (Henkel et al 2015:11)"announced a SPARQL endpoint for BioModels Database" (Henkel et al 2015:11)"Due to the missing index support for this RDF store, the user must first manually look up and transform this annotation term into a URL, and paste that into the query" (Henkel et al 2015:12)"Our system, in the contrary, is able to retrieve this information automatically by a simple index-based query" (Henkel et al 2015:12)"COMBINE Archive" (Henkel et al 2015:12)"CombineArchive Toolkit (62) may query our database, collect all necessary information" (Henkel et al 2015:12)"Conclusion" (Henkel et al 2015:12)"The system described in this article incorporates and links knowledge that is in principle already available in public repositories, but not yet utilized" (Henkel et al 2015:12)"knowledge is encoded in meta-data, in particular links to simulation experiments and semantic annotations with terms from bio-ontologies" (Henkel et al 2015:12)"Materials and methods" (Henkel et al 2015:12)"entry point for each model import is a document node" (Henkel et al 2015:12)"links to a model node via the directed edge hasModel" (Henkel et al 2015:12)"model node has a model name and relations" (Henkel et al 2015:12)"include species, compartments or reactions" (Henkel et al 2015:12)"species node is created and named hasSpecies" (Henkel et al 2015:12)"reaction and compartment are created and connected with hasReaction and hasComartment" (Henkel et al 2015:12)"species node is connected to a compartment node with isContainedIn" (Henkel et al 2015:12)"ensure an easy traversal upwards, a connection is created from each node of the stored model that points to the parent of the current node. The corresponding edges are named belongsTo" (Henkel et al 2015:12)"it is possible to attach an annotation to each model entity" (Henkel et al 2015:12)"This index is afterwards used for ranked model retrieval" (Henkel et al 2015:12)"Implementation" (Henkel et al 2015:12)"Neo4J (http://www. neo4j.org/) database stores model files, simulation descriptions and model-related information in a graph manner" (Henkel et al 2015:12)Neo4J database stores model files, simulation descrip-tions and model-related information in a graph manner (note on p.12)"retrieval engine is based on the ranked retrieval described in Henkel et al. (10)" (Henkel et al 2015:12)"Queries are resolved using the Lucene framework" (Henkel et al 2015:12)"data import pushes different data formats, including model code, simulation experiment descriptions and ontologies" (Henkel et al 2015:12)"Afterwards a post-process takes care of linking the added data of different domains" (Henkel et al 2015:13)"after adding an ontology to the database a post-processing is required to link model or simulation description entities to the newly added Ontology concepts" (Henkel et al 2015:13)},
  file = {Attachment:/home/martin/.mozilla/firefox/2czweqll.default/zotero/storage/EBAC8MWX/masymos.pdf:application/pdf}
}

@incollection{Schmidt2000,
  series = {Lecture Notes in Computer Science},
  title = {Efficient {{Relational Storage}} and {{Retrieval}} of {{XML Documents}}},
  copyright = {\textcopyright{}2001 Springer-Verlag Berlin Heidelberg},
  isbn = {978-3-540-41826-9 978-3-540-45271-3},
  abstract = {In this paper, we present a data and an execution model that allow for efficient storage and retrieval of XML documents in a relational database. The data model is strictly based on the notion of binary associations: by decomposing XML documents into small, flexible and semantically homogeneous units we are able to exploit the performance potential of vertical fragmentation. Moreover, our approach provides clear and intuitive semantics, which facilitates the definition of a declarative query algebra. Our experimental results with large collections of XML documents demonstrate the effectiveness of the techniques proposed.},
  language = {en},
  timestamp = {2016-08-29T08:27:03Z},
  number = {1997},
  urldate = {2016-08-29},
  url = {http://link.springer.com/chapter/10.1007/3-540-45271-0_9},
  booktitle = {The {{World Wide Web}} and {{Databases}}},
  publisher = {{Springer Berlin Heidelberg}},
  author = {Schmidt, Albrecht and Kersten, Martin and Windhouwer, Menzo and Waas, Florian},
  editor = {Goos, Gerhard and Hartmanis, Juris and van Leeuwen, Jan and Suciu, Dan and Vossen, Gottfried},
  month = may,
  year = {2000},
  keywords = {Computer Communication Networks,Database Management,Information Storage and Retrieval,Information Systems Applications (incl. Internet),IT in Business,Popular Computer Science},
  pages = {137--150},
  file = {Full Text PDF:/home/martin/.mozilla/firefox/2czweqll.default/zotero/storage/SF5U2VG4/Schmidt et al. - 2000 - Efficient Relational Storage and Retrieval of XML .pdf:application/pdf;Snapshot:/home/martin/.mozilla/firefox/2czweqll.default/zotero/storage/TDZBQVFG/3-540-45271-0_9.html:text/html},
  doi = {10.1007/3-540-45271-0_9}
}

@inproceedings{Ronnau2005,
  address = {New York, NY, USA},
  series = {DocEng '05},
  title = {Towards {{XML Version Control}} of {{Office Documents}}},
  isbn = {978-1-59593-240-2},
  doi = {10.1145/1096601.1096606},
  abstract = {Office applications such as OpenOffice and Microsoft Office are widely used to edit the majority of today's business documents: office documents. Usually, version control systems consider office documents as binary objects, thus severely hindering collaborative work. Since XML has become a de-facto standard for office applications, we focus on versioning office documents by structured XML version control approaches. This enables state-of-the-art version control for office documents.A basic prerequisite to XML version control is a diff algorithm, which detects structural changes between XML documents. In this paper, we evaluate state-of-the-art XML diff algorithms w.r.t. their suitability to OpenOffice XML documents and the future OASIS office document standard. It turns out that, due to the specific XML office format, a careful examination of the diff algorithm characteristics is necessary. Therefore, we identify important features for XML diff approaches to handle office documents. We have implemented a first OpenOffice versioning API that can be used in version control systems as a replacement for line-based or binary diffs, which are currently used.},
  timestamp = {2016-08-29T08:20:27Z},
  urldate = {2016-08-29},
  url = {http://doi.acm.org/10.1145/1096601.1096606},
  booktitle = {Proceedings of the 2005 {{ACM Symposium}} on {{Document Engineering}}},
  publisher = {{ACM}},
  author = {R{\"o}nnau, Sebastian and Scheffczyk, Jan and Borghoff, Uwe M.},
  year = {2005},
  keywords = {office applications,version control,XML diffing},
  pages = {10--19},
  file = {ACM Full Text PDF:/home/martin/.mozilla/firefox/2czweqll.default/zotero/storage/SNCCT8ZK/Rönnau et al. - 2005 - Towards XML Version Control of Office Documents.pdf:application/pdf}
}

@inproceedings{Chawathe1996,
  address = {New York, NY, USA},
  series = {SIGMOD '96},
  title = {Change {{Detection}} in {{Hierarchically Structured Information}}},
  isbn = {978-0-89791-794-0},
  doi = {10.1145/233269.233366},
  abstract = {Detecting and representing changes to data is important for active databases, data warehousing, view maintenance, and version and configuration management. Most previous work in change management has dealt with flat-file and relational data; we focus on hierarchically structured data. Since in many cases changes must be computed from old and new versions of the data, we define the hierarchical change detection problem as the problem of finding a "minimum-cost edit script" that transforms one data tree to another, and we present efficient algorithms for computing such an edit script. Our algorithms make use of some key domain characteristics to achieve substantially better performance than previous, general-purpose algorithms. We study the performance of our algorithms both analytically and empirically, and we describe the application of our techniques to hierarchically structured documents.},
  timestamp = {2016-08-29T08:18:44Z},
  urldate = {2016-08-29},
  url = {http://doi.acm.org/10.1145/233269.233366},
  booktitle = {Proceedings of the 1996 {{ACM SIGMOD International Conference}} on {{Management}} of {{Data}}},
  publisher = {{ACM}},
  author = {Chawathe, Sudarshan S. and Rajaraman, Anand and Garcia-Molina, Hector and Widom, Jennifer},
  year = {1996},
  pages = {493--504},
  file = {ACM Full Text PDF:/home/martin/.mozilla/firefox/2czweqll.default/zotero/storage/K57RNEWT/Chawathe et al. - 1996 - Change Detection in Hierarchically Structured Info.pdf:application/pdf}
}

@article{Peng2011,
  title = {Reproducible {{Research}} in {{Computational Science}}},
  volume = {334},
  copyright = {Copyright \textcopyright{} 2011, American Association for the Advancement of Science},
  issn = {0036-8075, 1095-9203},
  doi = {10.1126/science.1213847},
  abstract = {Computational science has led to exciting new developments, but the nature of the work has exposed limitations in our ability to evaluate published findings. Reproducibility has the potential to serve as a minimum standard for judging scientific claims when full independent replication of a study is not possible.},
  language = {en},
  timestamp = {2016-08-29T16:02:40Z},
  number = {6060},
  urldate = {2016-08-29},
  url = {http://science.sciencemag.org/content/334/6060/1226},
  journal = {Science},
  author = {Peng, Roger D.},
  month = dec,
  year = {2011},
  pages = {1226--1227},
  file = {Full Text PDF:/home/martin/.mozilla/firefox/2czweqll.default/zotero/storage/8QBKWBRU/Peng - 2011 - Reproducible Research in Computational Science.pdf:application/pdf;Snapshot:/home/martin/.mozilla/firefox/2czweqll.default/zotero/storage/V886SVZ6/1226.html:text/html},
  pmid = {22144613}
}

@book{Gentleman2005,
  series = {Volume 4, Issue 1},
  title = {Reproducible {{Research}}: {{A Bioinformatics Case Study}}},
  volume = {4},
  abstract = {While scientific research and the methodologies involved have gone through substantial tech
nological evolution the technology involved in the publication of the results of these endeavors has
remained relatively stagnant. Publication is largely done in the same manner today as it was fifty
years ago. Many journals have adopted electronic formats, however, their orientation and style is
little different from a printed document. The documents tend to be static and take little advantage
of computational resources that might be available. Recent work, Gentleman and Temple Lang
(2003), suggests a methodology and basic infrastructure that can be used to
publish
documents in
a substantially different way. Their approach is suitable for the publication of papers whose mes-
sage relies on computation. Stated quite simply, Gentleman and Temple Lang (2003) propose a
paradigm where documents are mixtures of code and text. Such documents may be self-contained
or they may be a component of a
compendium
which provides the infrastructure needed to provide
access to data and supporting software. These documents, or compendiums, can be processed in a
number of different ways. One transformation will be to replace the code with its output \textendash{} thereby
providing the familiar, but limited, static document.
$<$
p /
$>$
In this paper we apply these concepts
to a seminal paper in bioinformatics, namely
The Molecular Classification of Cancer
, Golub et al
(1999). The authors of that paper have generously provided data and other information that have
allowed us to largely reproduce their results. Rather than reproduce this paper exactly we demonstrate that such a reproduction is possible and instead concentrate on demonstrating the usefulness
of the compendium concept itself.},
  timestamp = {2016-08-29T14:47:18Z},
  number = {1},
  publisher = {{Statistical Applications in Genetics and Molecular Biology}},
  author = {Gentleman, Robert},
  year = {2005},
  file = {gentleman2005a.pdf:/home/martin/.mozilla/firefox/2czweqll.default/zotero/storage/CNV7HCF3/gentleman2005a.pdf:application/pdf}
}

@inproceedings{Wang2003,
  title = {X-{{Diff}}: An Effective Change Detection Algorithm for {{XML}} Documents},
  shorttitle = {X-{{Diff}}},
  doi = {10.1109/ICDE.2003.1260818},
  abstract = {XML has become the de facto standard format for Web publishing and data transportation. Since online information changes frequently, being able to quickly detect changes in XML documents is important to Internet query systems, search engines, and continuous query systems. Previous work in change detection on XML, or other hierarchically structured documents, used an ordered tree model, in which left-to-right order among siblings is important and it can affect the change result. We argue that an unordered model (only ancestor relationships are significant) is more suitable for most database applications. Using an unordered model, change detection is substantially harder than using the ordered model, but the change result that it generates is more accurate. We propose X-Diff, an effective algorithm that integrates key XML structure characteristics with standard tree-to-tree correction techniques. The algorithm is analyzed and compared with XyDiff [CAM02], a published XML diff algorithm. An experimental evaluation on both algorithms is provided.},
  timestamp = {2016-08-29T08:27:29Z},
  booktitle = {19th {{International Conference}} on {{Data Engineering}}, 2003. {{Proceedings}}},
  author = {Wang, Y. and DeWitt, D. J. and Cai, J. Y.},
  month = mar,
  year = {2003},
  keywords = {Algorithm design and analysis,Change detection algorithms,continuous query system,Databases,data transportation,Detection algorithms,document handling,electronic publishing,Internet,Internet query system,online information,ordered tree model,query formulation,search engine,Search engines,Standards publication,Transportation,tree data structures,tree-to-tree correction technique,Web publishing,X-Diff,XML,XML document,XML structure characteristic},
  pages = {519--530},
  file = {IEEE Xplore Full Text PDF:/home/martin/.mozilla/firefox/2czweqll.default/zotero/storage/6TK2JEVH/Wang et al. - 2003 - X-Diff an effective change detection algorithm fo.pdf:application/pdf;IEEE Xplore Abstract Record:/home/martin/.mozilla/firefox/2czweqll.default/zotero/storage/68TKW32F/1260818.html:text/html}
}

@article{McCullough2008,
  title = {Do Economics Journal Archives Promote Replicable Research?: {{Economics}} Journal Archives},
  volume = {41},
  issn = {00084085},
  shorttitle = {Do Economics Journal Archives Promote Replicable Research?},
  doi = {10.1111/j.1540-5982.2008.00509.x},
  language = {en},
  timestamp = {2016-08-31T12:01:50Z},
  number = {4},
  urldate = {2016-08-30},
  url = {http://doi.wiley.com/10.1111/j.1540-5982.2008.00509.x},
  journal = {Canadian Journal of Economics/Revue canadienne d'{\'e}conomique},
  author = {McCullough, B.D. and McGeary, Kerry Anne and Harrison, Teresa D.},
  month = sep,
  year = {2008},
  pages = {1406--1420},
  file = {McCullough et al. - 2008 - Do economics journal archives promote replicable r.pdf:/home/martin/.mozilla/firefox/2czweqll.default/zotero/storage/TPU867MM/McCullough et al. - 2008 - Do economics journal archives promote replicable r.pdf:application/pdf}
}

@article{Gennari2011,
  title = {Multiple Ontologies in Action: Composite Annotations for Biosimulation Models},
  volume = {44},
  issn = {1532-0480},
  shorttitle = {Multiple Ontologies in Action},
  doi = {10.1016/j.jbi.2010.06.007},
  abstract = {There now exists a rich set of ontologies that provide detailed semantics for biological entities of interest. However, there is not (nor should there be) a single source ontology that provides all the necessary semantics for describing biological phenomena. In the domain of physiological biosimulation models, researchers use annotations to convey semantics, and many of these annotations require the use of multiple reference ontologies. Therefore, we have developed the idea of composite annotations that access multiple ontologies to capture the physics-based meaning of model variables. These composite annotations provide the semantic expressivity needed to disambiguate the often-complex features of biosimulation models, and can be used to assist with model merging and interoperability. In this paper, we demonstrate the utility of composite annotations for model merging by describing their use within SemGen, our semantics-based model composition software. More broadly, if orthogonal reference ontologies are to meet their full potential, users need tools and methods to connect and link these ontologies. Our composite annotations and the SemGen tool provide one mechanism for leveraging multiple reference ontologies.},
  language = {eng},
  timestamp = {2016-09-08T15:56:04Z},
  number = {1},
  journal = {Journal of Biomedical Informatics},
  author = {Gennari, John H. and Neal, Maxwell L. and Galdzicki, Michal and Cook, Daniel L.},
  month = feb,
  year = {2011},
  keywords = {Anatomy,Biomedical Research,Computer Simulation,Databases; Factual,Documentation,Humans,Models; Biological,Semantics,Software},
  pages = {146--154},
  file = {1-s2.0-S1532046410000924-main.pdf:/home/martin/.mozilla/firefox/2czweqll.default/zotero/storage/QEFMCXCF/1-s2.0-S1532046410000924-main.pdf:application/pdf},
  pmid = {20601121},
  pmcid = {PMC2989341}
}

@article{Smith2007,
  title = {The {{OBO Foundry}}: Coordinated Evolution of Ontologies to Support Biomedical Data Integration},
  volume = {25},
  copyright = {\textcopyright{} 2007 Nature Publishing Group},
  issn = {1087-0156},
  shorttitle = {The {{OBO Foundry}}},
  doi = {10.1038/nbt1346},
  abstract = {The value of any kind of data is greatly enhanced when it exists in a form that allows it to be integrated with other data. One approach to integration is through the annotation of multiple bodies of data using common controlled vocabularies or 'ontologies'. Unfortunately, the very success of this approach has led to a proliferation of ontologies, which itself creates obstacles to integration. The Open Biomedical Ontologies (OBO) consortium is pursuing a strategy to overcome this problem. Existing OBO ontologies, including the Gene Ontology, are undergoing coordinated reform, and new ontologies are being created on the basis of an evolving set of shared principles governing ontology development. The result is an expanding family of ontologies designed to be interoperable and logically well formed and to incorporate accurate representations of biological reality. We describe this OBO Foundry initiative and provide guidelines for those who might wish to become involved.},
  language = {en},
  timestamp = {2016-09-08T15:58:02Z},
  number = {11},
  urldate = {2016-09-08},
  url = {http://www.nature.com/nbt/journal/v25/n11/full/nbt1346.html},
  journal = {Nature Biotechnology},
  author = {Smith, Barry and Ashburner, Michael and Rosse, Cornelius and Bard, Jonathan and Bug, William and Ceusters, Werner and Goldberg, Louis J. and Eilbeck, Karen and Ireland, Amelia and Mungall, Christopher J. and Leontis, Neocles and Rocca-Serra, Philippe and Ruttenberg, Alan and Sansone, Susanna-Assunta and Scheuermann, Richard H. and Shah, Nigam and Whetzel, Patricia L. and Lewis, Suzanna},
  month = nov,
  year = {2007},
  pages = {1251--1255},
  file = {Full Text PDF:/home/martin/.mozilla/firefox/2czweqll.default/zotero/storage/GWV3IFPE/Smith et al. - 2007 - The OBO Foundry coordinated evolution of ontologi.pdf:application/pdf;Snapshot:/home/martin/.mozilla/firefox/2czweqll.default/zotero/storage/JUJHF2EU/nbt1346.html:text/html}
}

@article{Ashburner2000,
  title = {Gene {{Ontology}}: Tool for the Unification of Biology},
  volume = {25},
  issn = {1061-4036},
  shorttitle = {Gene {{Ontology}}},
  doi = {10.1038/75556},
  abstract = {Genomic sequencing has made it clear that a large fraction of the genes specifying the core biological functions are shared by all eukaryotes. Knowledge of the biological role of such shared proteins in one organism can often be transferred to other organisms. The goal of the Gene Ontology Consortium is to produce a dynamic, controlled vocabulary that can be applied to all eukaryotes even as knowledge of gene and protein roles in cells is accumulating and changing. To this end, three independent ontologies accessible on the World-Wide Web (http://www.geneontology.org) are being constructed: biological process, molecular function and cellular component.},
  timestamp = {2016-09-08T15:55:53Z},
  number = {1},
  urldate = {2016-09-08},
  url = {http://www.ncbi.nlm.nih.gov/pmc/articles/PMC3037419/},
  journal = {Nature genetics},
  author = {Ashburner, Michael and Ball, Catherine A. and Blake, Judith A. and Botstein, David and Butler, Heather and Cherry, J. Michael and Davis, Allan P. and Dolinski, Kara and Dwight, Selina S. and Eppig, Janan T. and Harris, Midori A. and Hill, David P. and Issel-Tarver, Laurie and Kasarskis, Andrew and Lewis, Suzanna and Matese, John C. and Richardson, Joel E. and Ringwald, Martin and Rubin, Gerald M. and Sherlock, Gavin},
  month = may,
  year = {2000},
  pages = {25--29},
  file = {PubMed Central Full Text PDF:/home/martin/.mozilla/firefox/2czweqll.default/zotero/storage/NFQMRXEK/Ashburner et al. - 2000 - Gene Ontology tool for the unification of biology.pdf:application/pdf},
  pmid = {10802651},
  pmcid = {PMC3037419}
}

@article{Prinz2011,
  title = {Believe It or Not: How Much Can We Rely on Published Data on Potential Drug Targets?},
  volume = {10},
  copyright = {\textcopyright{} 2011 Nature Publishing Group},
  issn = {1474-1776},
  shorttitle = {Believe It or Not},
  doi = {10.1038/nrd3439-c1},
  language = {en},
  timestamp = {2016-09-12T11:42:18Z},
  number = {9},
  urldate = {2016-09-12},
  url = {http://www.nature.com/nrd/journal/v10/n9/full/nrd3439-c1.html},
  journal = {Nature Reviews Drug Discovery},
  author = {Prinz, Florian and Schlange, Thomas and Asadullah, Khusru},
  month = sep,
  year = {2011},
  pages = {712--712},
  file = {Full Text PDF:/home/martin/.mozilla/firefox/2czweqll.default/zotero/storage/8PJM3GH5/Prinz et al. - 2011 - Believe it or not how much can we rely on publish.pdf:application/pdf;Snapshot:/home/martin/.mozilla/firefox/2czweqll.default/zotero/storage/P8DMUQ8R/nrd3439-c1.html:text/html}
}

@misc{Bergmann2014,
  title = {{{COMBINE Archive Specification Version}} 1},
  language = {eng},
  timestamp = {2016-09-12T13:20:09Z},
  url = {http://co.mbine.org/specifications/omex.version-1.pdf},
  author = {Bergmann, Frank T and Rodriguez, Nicolas and Le Nov{\`e}re, Nicolas},
  month = sep,
  year = {2014},
  file = {COMBINE Archive Specification - omex.version-1.pdf:/home/martin/.mozilla/firefox/2czweqll.default/zotero/storage/WRXE92NH/omex.version-1.pdf:application/pdf}
}

@article{Bergmann2014a,
  title = {One File to Share Them All: {{Using}} the {{COMBINE Archive}} and the {{OMEX}} Format to Share All Information about a Modeling Project},
  shorttitle = {One File to Share Them All},
  abstract = {Background: With the ever increasing use of computational models in the biosciences, the need to share models and reproduce the results of published studies efficiently and easily is becoming more important. To this end, various standards have been proposed that can be used to describe models, simulations, data or other essential information in a consistent fashion. These constitute various separate components required to reproduce a given published scientific result. Results: We describe the Open Modeling EXchange format (OMEX). Together with the use of other standard formats from the Computational Modeling in Biology Network (COMBINE), OMEX is the basis of the COMBINE Archive, a single file that supports the exchange of all the information necessary for a modeling and simulation experiment in biology. An OMEX file is a ZIP container that includes a manifest file, listing the content of the archive, an optional metadata file adding information about the archive and its content, and the files describing the model. The content of a COMBINE Archive consists of files encoded in COMBINE standards whenever possible, but may include additional files defined by an Internet Media Type. Several tools that support the COMBINE Archive are available, either as independent libraries or embedded in modeling software. Conclusions: The COMBINE Archive facilitates the reproduction of modeling and simulation experiments in biology by embedding all the relevant information in one file. Having all the information stored and exchanged at once also helps in building activity logs and audit trails. We anticipate that the COMBINE Archive will become a significant help for modellers, as the domain moves to larger, more complex experiments such as multi-scale models of organs, digital organisms, and bioengineering.},
  timestamp = {2016-10-02T21:08:48Z},
  archivePrefix = {arXiv},
  eprinttype = {arxiv},
  eprint = {1407.4992},
  primaryClass = {cs, q-bio},
  urldate = {2016-09-13},
  url = {http://arxiv.org/abs/1407.4992},
  journal = {arXiv:1407.4992 [cs, q-bio]},
  author = {Bergmann, Frank T. and Adams, Richard and Moodie, Stuart and Cooper, Jonathan and Glont, Mihai and Golebiewski, Martin and Hucka, Michael and Laibe, Camille and Miller, Andrew K. and Nickerson, David P. and Olivier, Brett G. and Rodriguez, Nicolas and Sauro, Herbert M. and Scharm, Martin and Soiland-Reyes, Stian and Waltemath, Dagmar and Yvon, Florent and Nov{\`e}re, Nicolas Le},
  month = jul,
  year = {2014},
  keywords = {Computer Science - Digital Libraries,Quantitative Biology - Molecular Networks},
  annote = {Comment: 3 figures, 1 table},
  file = {arXiv\:1407.4992 PDF:/home/martin/.mozilla/firefox/2czweqll.default/zotero/storage/M2ZBDEMG/Bergmann et al. - 2014 - One file to share them all Using the COMBINE Arch.pdf:application/pdf;arXiv.org Snapshot:/home/martin/.mozilla/firefox/2czweqll.default/zotero/storage/RXQXKFRQ/1407.html:text/html}
}

@misc{COMBINE,
  title = {Coordinating Standards for Modeling in Biology | {{COMBINE}}},
  timestamp = {2016-10-02T21:08:48Z},
  urldate = {2016-10-02},
  url = {http://co.mbine.org/},
  author = {{COMBINE}},
  file = {Coordinating standards for modeling in biology | COMBINE:/home/martin/.mozilla/firefox/2czweqll.default/zotero/storage/BKVVRQES/co.mbine.org.html:text/html}
}

@book{Saake2010,
  address = {Heidelberg Hamburg},
  edition = {4. Aufl},
  series = {Biber-Buch},
  title = {{Datenbanken: Konzepte und Sprachen}},
  isbn = {978-3-8266-9057-0},
  shorttitle = {{Datenbanken}},
  language = {ger},
  timestamp = {2016-10-10T09:54:14Z},
  publisher = {{mitp, Verl.-Gruppe H{\"u}thig, Jehle, Rehm}},
  author = {Saake, Gunter and Sattler, Kai-Uwe and Heuer, Andreas},
  year = {2010},
  note = {OCLC: 680676568},
  keywords = {Datenbankentwurf,Datenbanksprache,Datenbanksystem},
  annote = {Literaturverz. S. 729 - 750},
  file = {Table of Contents PDF:/home/martin/.mozilla/firefox/2czweqll.default/zotero/storage/ZTK2XG7X/Saake et al. - 2010 - Datenbanken Konzepte und Sprachen.pdf:application/pdf}
}

@article{Lysenko2016,
  title = {Representing and Querying Disease Networks Using Graph Databases},
  volume = {9},
  issn = {1756-0381},
  doi = {10.1186/s13040-016-0102-8},
  language = {en},
  timestamp = {2016-10-10T08:56:34Z},
  number = {1},
  urldate = {2016-10-10},
  url = {http://biodatamining.biomedcentral.com/articles/10.1186/s13040-016-0102-8},
  journal = {BioData Mining},
  author = {Lysenko, Artem and Roznov{\u a}{\c t}, Irina A. and Saqi, Mansoor and Mazein, Alexander and Rawlings, Christopher J and Auffray, Charles},
  month = dec,
  year = {2016},
  file = {Lysenko et al. - 2016 - Representing and querying disease networks using g.pdf:/home/martin/.mozilla/firefox/2czweqll.default/zotero/storage/FXTEXR8C/Lysenko et al. - 2016 - Representing and querying disease networks using g.pdf:application/pdf}
}

@inproceedings{Tudorica2011,
  title = {A Comparison between Several {{NoSQL}} Databases with Comments and Notes},
  doi = {10.1109/RoEduNet.2011.5993686},
  abstract = {This paper is trying to comment on the various NoSQL (Not only Structured Query Language) systems and to make a comparison (using multiple criteria) between them. The NoSQL databases were created as a mean to offer high performance (both in terms of speed and size) and high availability at the price of loosing the ACID (Atomic, Consistent, Isolated, Durable) trait of the traditional databases in exchange with keeping a weaker BASE (Basic Availability, Soft state, Eventual consistency) feature. Remains to be seen which of the multiple solutions created since the official appearance of the NoSQL concept (which was defined in 1998 and reintroduced in 2009, around which moment several NoSQL solutions emerged; at the present moment there are known over 120 such solutions) are really delivering on these promises of higher performance (although several of them are already used with very good results).},
  timestamp = {2016-10-10T12:48:22Z},
  booktitle = {2011 {{RoEduNet International Conference}} 10th {{Edition}}: {{Networking}} in {{Education}} and {{Research}}},
  author = {Tudorica, B. G. and Bucur, C.},
  month = jun,
  year = {2011},
  keywords = {ACID,atomic consistent isolated durable database trait,Availability,BASE,basic availability soft state eventual consistency feature,Benchmark testing,comparison,database,Distributed databases,Generators,Google,NoSQL,NoSQL databases,not only structured query language systems,performance,SQL,Taxonomy},
  pages = {1--5},
  file = {IEEE Xplore Full Text PDF:/home/martin/.mozilla/firefox/2czweqll.default/zotero/storage/IUTNH4J8/Tudorica and Bucur - 2011 - A comparison between several NoSQL databases with .pdf:application/pdf;IEEE Xplore Abstract Record:/home/martin/.mozilla/firefox/2czweqll.default/zotero/storage/E6SMQZTP/5993686.html:text/html}
}

@article{Teorey1986,
  title = {A {{Logical Design Methodology}} for {{Relational Databases Using}} the {{Extended Entity}}-Relationship {{Model}}},
  volume = {18},
  issn = {0360-0300},
  doi = {10.1145/7474.7475},
  abstract = {A database design methodology is defined for the design of large relational databases. First, the data requirements are conceptualized using an extended entity-relationship model, with the extensions being additional semantics such as ternary relationships, optional relationships, and the generalization abstraction. The extended entity-relationship model is then decomposed according to a set of basic entity-relationship constructs, and these are transformed into candidate relations. A set of basic transformations has been developed for the three types of relations: entity relations, extended entity relations, and relationship relations. Candidate relations are further analyzed and modified to attain the highest degree of normalization desired.
The methodology produces database designs that are not only accurate representations of reality, but flexible enough to accommodate future processing requirements. It also reduces the number of data dependencies that must be analyzed, using the extended ER model conceptualization, and maintains data integrity through normalization. This approach can be implemented manually or in a simple software package as long as a "good" solution is acceptable and absolute optimality is not required.},
  timestamp = {2016-10-10T09:50:24Z},
  number = {2},
  urldate = {2016-10-10},
  url = {http://doi.acm.org/10.1145/7474.7475},
  journal = {ACM Comput. Surv.},
  author = {Teorey, Toby J. and Yang, Dongqing and Fry, James P.},
  month = jun,
  year = {1986},
  pages = {197--222},
  file = {ACM Full Text PDF:/home/martin/.mozilla/firefox/2czweqll.default/zotero/storage/V7RRXJZP/Teorey et al. - 1986 - A Logical Design Methodology for Relational Databa.pdf:application/pdf}
}

@article{Courtot2011,
  title = {Controlled Vocabularies and Semantics in Systems Biology},
  volume = {7},
  copyright = {Copyright \textcopyright{} 2011 EMBO and Macmillan Publishers Limited. This is an open-access article distributed under the terms of the Creative Commons Attribution License, which permits distribution, and reproduction in any medium, provided the original author and source are credited. This license does not permit commercial exploitation without specific permission.},
  issn = {1744-4292, 1744-4292},
  doi = {10.1038/msb.2011.77},
  abstract = {The use of computational modeling to describe and analyze biological systems is at the heart of systems biology. Model structures, simulation descriptions and numerical results can be encoded in structured formats, but there is an increasing need to provide an additional semantic layer. Semantic information adds meaning to components of structured descriptions to help identify and interpret them unambiguously. Ontologies are one of the tools frequently used for this purpose. We describe here three ontologies created specifically to address the needs of the systems biology community. The Systems Biology Ontology (SBO) provides semantic information about the model components. The Kinetic Simulation Algorithm Ontology (KiSAO) supplies information about existing algorithms available for the simulation of systems biology models, their characterization and interrelationships. The Terminology for the Description of Dynamics (TEDDY) categorizes dynamical features of the simulation results and general systems behavior. The provision of semantic information extends a model's longevity and facilitates its reuse. It provides useful insight into the biology of modeled processes, and may be used to make informed decisions on subsequent simulation experiments.},
  language = {en},
  timestamp = {2016-10-10T08:39:20Z},
  number = {1},
  urldate = {2016-10-10},
  url = {http://msb.embopress.org/content/7/1/543},
  journal = {Molecular Systems Biology},
  author = {Courtot, M{\'e}lanie and Juty, Nick and Kn{\"u}pfer, Christian and Waltemath, Dagmar and Zhukova, Anna and Dr{\"a}ger, Andreas and Dumontier, Michel and Finney, Andrew and Golebiewski, Martin and Hastings, Janna and Hoops, Stefan and Keating, Sarah and Kell, Douglas B. and Kerrien, Samuel and Lawson, James and Lister, Allyson and Lu, James and Machne, Rainer and Mendes, Pedro and Pocock, Matthew and Rodriguez, Nicolas and Villeger, Alice and Wilkinson, Darren J. and Wimalaratne, Sarala and Laibe, Camille and Hucka, Michael and Nov{\`e}re, Nicolas Le},
  month = jan,
  year = {2011},
  keywords = {dynamics,kinetics,model,ontology,simulation},
  pages = {543},
  file = {Full Text PDF:/home/martin/.mozilla/firefox/2czweqll.default/zotero/storage/NXUFBDNV/Courtot et al. - 2011 - Controlled vocabularies and semantics in systems b.pdf:application/pdf;Snapshot:/home/martin/.mozilla/firefox/2czweqll.default/zotero/storage/ENN6QFVV/543.html:text/html},
  pmid = {22027554}
}

@article{Finkelstein2004,
  title = {Computational Challenges of Systems Biology},
  volume = {37},
  issn = {0018-9162},
  doi = {10.1109/MC.2004.1297236},
  timestamp = {2016-10-12T09:01:19Z},
  number = {5},
  urldate = {2016-10-12},
  url = {http://ieeexplore.ieee.org/document/1297236/},
  journal = {Computer},
  author = {Finkelstein, A. and Hetherington, J. and {Linzhong Li} and Margoninski, O. and Saffrey, P. and Seymour, R. and Warner, A.},
  month = may,
  year = {2004},
  pages = {26--33},
  file = {Finkelstein et al. - 2004 - Computational challenges of systems biology.pdf:/home/martin/.mozilla/firefox/2czweqll.default/zotero/storage/PA4GW5HB/Finkelstein et al. - 2004 - Computational challenges of systems biology.pdf:application/pdf}
}

@article{Henkel2010,
  title = {Ranked Retrieval of {{Computational Biology}} Models},
  volume = {11},
  issn = {1471-2105},
  doi = {10.1186/1471-2105-11-423},
  abstract = {The study of biological systems demands computational support. If targeting a biological problem, the reuse of existing computational models can save time and effort. Deciding for potentially suitable models, however, becomes more challenging with the increasing number of computational models available, and even more when considering the models' growing complexity. Firstly, among a set of potential model candidates it is difficult to decide for the model that best suits ones needs. Secondly, it is hard to grasp the nature of an unknown model listed in a search result set, and to judge how well it fits for the particular problem one has in mind.},
  timestamp = {2016-10-12T09:01:49Z},
  urldate = {2016-10-12},
  url = {http://dx.doi.org/10.1186/1471-2105-11-423},
  journal = {BMC Bioinformatics},
  author = {Henkel, Ron and Endler, Lukas and Peters, Andre and Le Nov{\`e}re, Nicolas and Waltemath, Dagmar},
  year = {2010},
  pages = {423},
  annote = {Pages 423 in PDF},
  file = {Full Text PDF:/home/martin/.mozilla/firefox/2czweqll.default/zotero/storage/23X7MPAH/Henkel et al. - 2010 - Ranked retrieval of Computational Biology models.pdf:application/pdf;Snapshot:/home/martin/.mozilla/firefox/2czweqll.default/zotero/storage/XI4SNTVZ/1471-2105-11-423.html:text/html}
}

@inproceedings{Henkel2012,
  title = {Considerations of Graph-Based Concepts to Manage of Computational Biology Models and Associated Simulations},
  abstract = {Over the past years various databases in Life Sciences have been developed , among them databases to handle computational models of biological systems. Exchange formats that represent these models are typically XML-based; they encode models as networks. Models are published together with supplementary materials such as annotations, simulation experiment descriptions , or result sets. In consequence, not only model files need to be managed, but also the associated simulation setups, and highly linked meta-information. We discuss here the use of graph databases for model storage as they well reflect this interrelated nature. They can also enhance the integrated management of computational models and associated meta-information, as they handle connections between models, simulation descriptions and result data files, as well as external knowledge. This property enhances version control, retrieval and ranking, thereby resulting in improved model reuse and result reproducibility. 1 Background Systems Biology is the study of complex biological systems by means of computational approaches and methods. A computational model of a biological system represents aspects of that system, often using mathematical equations. Modeling has become a major tool in the daily work of systems biologists. Consequently, the number of available models has grown steadily over the last decade, and so has the models\&\#39; complexity [He10]. To reuse existing model code, the code itself must, first, be made available in model databases. Second, it must be encoded in exchangeable standard formats, which can then be interpreted by software tools. BioModels Database [Li10] is one example of an open model repository that freely distributes models in standard format. Together with the model, a whole plethora of meta-information is provided,},
  timestamp = {2016-10-12T09:12:42Z},
  urldate = {2016-10-12},
  url = {https://www.semanticscholar.org/paper/Considerations-of-graph-based-concepts-to-manage-Henkel-Nov\%C3\%A8re/54cc566f334063fc744d3348bd0f52ec916fd448},
  author = {Henkel, Ron and Le Nov{\`e}re, Nicolas and Wolkenhauer, Olaf and Waltemath, Dagmar},
  year = {2012},
  keywords = {Biological Systems,Metainformation},
  file = {Considerations of graph-based concepts to manage o.pdf:/home/martin/.mozilla/firefox/2czweqll.default/zotero/storage/FVNSU9NB/Considerations of graph-based concepts to manage o.pdf:application/pdf;Snapshot:/home/martin/.mozilla/firefox/2czweqll.default/zotero/storage/KSM65ETH/54cc566f334063fc744d3348bd0f52ec916fd448.html:text/html}
}

@article{Li2010,
  title = {{{BioModels Database}}: {{An}} Enhanced, Curated and Annotated Resource for Published Quantitative Kinetic Models},
  volume = {4},
  issn = {1752-0509},
  shorttitle = {{{BioModels Database}}},
  doi = {10.1186/1752-0509-4-92},
  abstract = {Quantitative models of biochemical and cellular systems are used to answer a variety of questions in the biological sciences. The number of published quantitative models is growing steadily thanks to increasing interest in the use of models as well as the development of improved software systems and the availability of better, cheaper computer hardware. To maximise the benefits of this growing body of models, the field needs centralised model repositories that will encourage, facilitate and promote model dissemination and reuse. Ideally, the models stored in these repositories should be extensively tested and encoded in community-supported and standardised formats. In addition, the models and their components should be cross-referenced with other resources in order to allow their unambiguous identification.},
  timestamp = {2016-10-12T11:54:37Z},
  urldate = {2016-10-12},
  url = {http://dx.doi.org/10.1186/1752-0509-4-92},
  journal = {BMC Systems Biology},
  author = {Li, Chen and Donizelli, Marco and Rodriguez, Nicolas and Dharuri, Harish and Endler, Lukas and Chelliah, Vijayalakshmi and Li, Lu and He, Enuo and Henry, Arnaud and Stefan, Melanie I. and Snoep, Jacky L. and Hucka, Michael and Le Nov{\`e}re, Nicolas and Laibe, Camille},
  year = {2010},
  pages = {92},
  annote = {Pages 92 in PDF},
  file = {Full Text PDF:/home/martin/.mozilla/firefox/2czweqll.default/zotero/storage/6CACSX6Q/Li et al. - 2010 - BioModels Database An enhanced, curated and annot.pdf:application/pdf;Snapshot:/home/martin/.mozilla/firefox/2czweqll.default/zotero/storage/2K9S2VNU/1752-0509-4-92.html:text/html}
}

@article{Yu2011,
  title = {The {{Physiome Model Repository}} 2},
  volume = {27},
  issn = {1367-4803, 1460-2059},
  doi = {10.1093/bioinformatics/btq723},
  abstract = {Motivation: The Physiome Model Repository 2 (PMR2) software was created as part of the IUPS Physiome Project (Hunter and Borg, 2003), and today it serves as the foundation for the CellML model repository. Key advantages brought to the end user by PMR2 include: facilities for model exchange, enhanced collaboration and a detailed change history for each model.
Availability: PMR2 is available under an open source license at http://www.cellml.org/tools/pmr/; a fully functional instance of this software can be accessed at http://models.physiomeproject.org/.
Contact: tommy.yu\{at\}auckland.ac.nz},
  language = {en},
  timestamp = {2016-10-12T11:57:40Z},
  number = {5},
  urldate = {2016-10-12},
  url = {http://bioinformatics.oxfordjournals.org/content/27/5/743},
  journal = {Bioinformatics},
  author = {Yu, Tommy and Lloyd, Catherine M. and Nickerson, David P. and Cooling, Michael T. and Miller, Andrew K. and Garny, Alan and Terkildsen, Jonna R. and Lawson, James and Britten, Randall D. and Hunter, Peter J. and Nielsen, Poul M. F.},
  month = jan,
  year = {2011},
  pages = {743--744},
  file = {Full Text PDF:/home/martin/.mozilla/firefox/2czweqll.default/zotero/storage/WXKNZ545/Yu et al. - 2011 - The Physiome Model Repository 2.pdf:application/pdf;Snapshot:/home/martin/.mozilla/firefox/2czweqll.default/zotero/storage/G8SKD7V8/743.html:text/html},
  pmid = {21216774}
}

@incollection{Bechhofer2009,
  title = {{{OWL}}: {{Web Ontology Language}}},
  copyright = {\textcopyright{}2009 Springer Science+Business Media, LLC},
  isbn = {978-0-387-35544-3 978-0-387-39940-9},
  shorttitle = {{{OWL}}},
  abstract = {SynonymsWeb ontology languageDefinitionThe Web Ontology Language OWL is a language for defining ontologies on the Web. An OWL Ontology describes a domain in terms of classes, properties and individuals and may include rich descriptions of the characteristics of those objects. OWL ontologies can be used to describe the properties of Web resources. Where earlier representation languages have been used to develop tools and ontologies for specific user-communities in areas such as sciences, health and e-commerce, they were not necessarily designed to be compatible with the World Wide Web, or more specifically the Semantic Web, as is the case with OWL.Features of OWL are a collection of expressive operators for concept description including boolean operators (intersection, union and complement), plus explicit quantifiers for properties and relationships; the ability to specify characteristics of properties, such as transitivity or domains and ranges; a well defined semanti ...},
  language = {en},
  timestamp = {2016-10-13T12:57:34Z},
  urldate = {2016-10-13},
  url = {http://link.springer.com/referenceworkentry/10.1007/978-0-387-39940-9_1073},
  booktitle = {Encyclopedia of {{Database Systems}}},
  publisher = {{Springer US}},
  author = {Bechhofer, Sean},
  editor = {LIU, LING and {\"O}ZSU, M. TAMER},
  year = {2009},
  keywords = {Computer Communication Networks,Computer Imaging; Vision; Pattern Recognition and Graphics,Database Management,Information Storage and Retrieval,Information Systems Applications (incl. Internet),Multimedia Information Systems},
  pages = {2008--2009},
  file = {Snapshot:/home/martin/.mozilla/firefox/2czweqll.default/zotero/storage/7XKJ9VZF/10.html:text/html},
  doi = {10.1007/978-0-387-39940-9_1073}
}

@article{Berners-Lee2001,
  title = {The Semantic Web},
  volume = {284},
  timestamp = {2016-10-13T13:07:53Z},
  number = {5},
  journal = {Scientific american},
  author = {Berners-Lee, Tim and Hendler, James and Lassila, Ora},
  year = {2001},
  pages = {28--37},
  file = {Berners-Lee et al. - 2001 - The semantic web.pdf:/home/martin/.mozilla/firefox/2czweqll.default/zotero/storage/5HREM4PV/Berners-Lee et al. - 2001 - The semantic web.pdf:application/pdf}
}

@article{Berners-Lee2001a,
  title = {Publishing on the Semantic Web},
  volume = {410},
  copyright = {\textcopyright{} 2001 Nature Publishing Group},
  issn = {0028-0836},
  doi = {10.1038/35074206},
  abstract = {The coming Internet revolution will profoundly affect scientific information.},
  language = {en},
  timestamp = {2016-10-13T13:17:31Z},
  number = {6832},
  urldate = {2016-10-13},
  url = {http://www.nature.com/nature/journal/v410/n6832/full/4101023b0.html},
  journal = {Nature},
  author = {Berners-Lee, Tim and Hendler, James},
  month = apr,
  year = {2001},
  pages = {1023--1024},
  file = {Full Text PDF:/home/martin/.mozilla/firefox/2czweqll.default/zotero/storage/EDU29T3Z/Berners-Lee and Hendler - 2001 - Publishing on the semantic web.pdf:application/pdf;Snapshot:/home/martin/.mozilla/firefox/2czweqll.default/zotero/storage/53ZDFRC6/4101023b0.html:text/html}
}

@article{Shadbolt2006,
  title = {The {{Semantic Web Revisited}}},
  volume = {21},
  issn = {1541-1672},
  doi = {10.1109/MIS.2006.62},
  abstract = {The article included many scenarios in which intelligent agents and bots undertook tasks on behalf of their human or corporate owners. Of course, shopbots and auction bots abound on the Web, but these are essentially handcrafted for particular tasks: they have little ability to interact with heterogeneous data and information types. Because we haven't yet delivered large-scale, agent-based mediation, some commentators argue that the semantic Web has failed to deliver. We argue that agents can only flourish when standards are well established and that the Web standards for expressing shared meaning have progressed steadily over the past five years},
  timestamp = {2016-10-14T12:43:28Z},
  number = {3},
  journal = {IEEE Intelligent Systems},
  author = {Shadbolt, N. and Berners-Lee, T. and Hall, W.},
  month = jan,
  year = {2006},
  keywords = {agent-based mediation,Artificial intelligence,Bioinformatics,e-science,Genomics,heterogeneous data,Humans,intelligent agents,Intelligent systems,multi-agent systems,Ontologies,Recruitment,Search engines,semantic networks,semantic Web,standards,Web services,Web sites},
  pages = {96--101},
  file = {IEEE Xplore Full Text PDF:/home/martin/.mozilla/firefox/2czweqll.default/zotero/storage/FPVJWD8R/Shadbolt et al. - 2006 - The Semantic Web Revisited.pdf:application/pdf;IEEE Xplore Abstract Record:/home/martin/.mozilla/firefox/2czweqll.default/zotero/storage/ERSTNE5K/1637364.html:text/html}
}

@misc{Bechhofer2004,
  title = {{{OWL Web Ontology Language Reference}}},
  abstract = {The Web Ontology Language OWL is a semantic markup language for publishing and sharing ontologies on the World Wide Web. OWL is developed as a vocabulary extension of RDF (the Resource Description Framework) and is derived from the DAML+OIL Web Ontology Language. This document contains a structured informal description of the full set of OWL language constructs and is meant to serve as a reference for OWL users who want to construct OWL ontologies.},
  timestamp = {2016-10-14T18:17:45Z},
  urldate = {2016-10-14},
  url = {https://www.w3.org/TR/owl-ref/},
  journal = {OWL Web Ontology Language Reference},
  author = {Bechhofer, Sean and {van Harmelen}, Frank and Hendler, Jime and Horrocks, Ian and McGuinness, Deborah L. and Patel-Schneider, Peter F. and Stein, Lynn Andrea},
  month = feb,
  year = {2004},
  file = {OWL Web Ontology Language Reference:/home/martin/.mozilla/firefox/2czweqll.default/zotero/storage/TG4NG2EH/owl-ref.html:text/html}
}

@book{Robinson2013,
  address = {Beijing ; Sebastopol, CA},
  edition = {First edition},
  title = {Graph Databases},
  isbn = {978-1-4493-5626-2},
  lccn = {QA76.9.D3 R6455 2013},
  timestamp = {2016-10-15T09:31:34Z},
  publisher = {{O'Reilly}},
  author = {Robinson, Ian and Webber, James and Eifrem, Emil},
  year = {2013},
  note = {OCLC: ocn829452424},
  keywords = {Database design,Database Management,Databases,Data processing,Graph theory},
  annote = {Options for storing connected data -- Data modeling with graphs -- Building a graph database application -- Graphs in the real world -- Graph database internals -- Predictive analysis with graph theory -- NOSQL overview}
}

@book{Collins-Sussman2004,
  address = {Sebastopol, CA},
  edition = {1st ed},
  title = {Version Control with {{Subversion}}},
  isbn = {978-0-596-00448-4},
  lccn = {QA76.6 .C6274 2004},
  timestamp = {2016-10-24T09:26:27Z},
  publisher = {{O'Reilly Media}},
  author = {Collins-Sussman, Ben and Fitzpatrick, Brian W. and Pilato, C. Michael},
  year = {2004},
  note = {OCLC: ocm56018869},
  keywords = {Computer software,Development,Open source software,Subversion (Computer file)},
  annote = {"Next generation open source version control"--Cover}
}

@article{Spinellis2005,
  title = {Version Control Systems},
  volume = {22},
  issn = {0740-7459},
  doi = {10.1109/MS.2005.140},
  abstract = {Sane programmers don't write production code without the help of an editor and an interpreter or a compiler, yet the author has seen many software projects limping along without using a version control system. We can explain this contrast if we think in terms of the increased start-up costs and delayed gratification associated with adopting a VCS. We humans typically discount the future, and therefore implementing version control in a project appears to be a fight against human nature. It's true that you can't beat the productivity boost that compilers and editors provide, but four decades after punched-card programming in assembly language has gone out of fashion, we must now look elsewhere for our next efficiency gains. And if you or your project isn't using a VCS, adopting one might well be the single most important tooling improvement you can undertake.},
  timestamp = {2016-10-24T11:09:11Z},
  number = {5},
  journal = {IEEE Software},
  author = {Spinellis, D.},
  month = sep,
  year = {2005},
  keywords = {assembly language,Best practices,Books,configuration management,Control systems,Data mining,Documentation,Graphical user interfaces,History,production code,programming,punched-card programming,software engineering,Software testing,VCS,version control system,version control systems,Web pages,Writing},
  pages = {108--109},
  file = {IEEE Xplore Full Text PDF:/home/martin/.mozilla/firefox/2czweqll.default/zotero/storage/UZHIXUTQ/Spinellis - 2005 - Version control systems.pdf:application/pdf;IEEE Xplore Abstract Record:/home/martin/.mozilla/firefox/2czweqll.default/zotero/storage/ZH5X8NB4/1504674.html:text/html}
}

@patent{zotero-null-197,
  title = {Version Control System for Geographically Distributed Software Development},
  abstract = {A data processing system and method for controlling files at a local development site within a geographically distributed multisite software development project includes a storage device, a processor, a mastership enforcer and an exchanger. The storage device stores a local replica including a plurality of files. Each file comprises a plurality of branches, and each branch comprises a plurality of versions of the file. The processor executes instructions, and retrieves and stores versions of the files in the storage device. The mastership enforcer provides the processor with the exclusive capability to modify specific branches by adding new versions of target files as determined by multisite mastership rules. The processor can create new versions of the target files, which are stored in the local replica within the storage device. The exchanger periodically updates the local replica by exporting the new versions of the target files to remote replicas at geographically remote development sites and importing additional new versions of the files from remote replicas. Thus, different branches of files, which are stored in multiple replicas geographically distributed at various development sites, can be modified concurrently and the replicas are updated with each others modifications periodically, without losing modifications or allowing inconsistent modifications among the replicas.},
  timestamp = {2016-10-24T11:16:35Z},
  urldate = {2016-10-24},
  url = {http://www.google.com/patents/US5675802},
  note = {US-Klassifikation 717/103, 717/121, 707/E17.005, 707/999.203, 707/999.202; Internationale Klassifikation G06F17/30, G06F9/44;  Unternehmensklassifikation Y10S707/99954, G06F17/30575, G06F8/71, Y10S707/99953;  Europ{\"a}ische Klassifikation G06F8/71, G06F17/30S7}
}

@article{Schmoldt1975,
  title = {Digitoxin Metabolism by Rat Liver Microsomes},
  volume = {24},
  issn = {0006-2952},
  language = {ENG},
  timestamp = {2016-10-24T11:18:27Z},
  number = {17},
  journal = {Biochemical Pharmacology},
  author = {Schmoldt, A. and Benthe, H. F. and Haberland, G.},
  month = sep,
  year = {1975},
  keywords = {Animals,Chromatography; Thin Layer,Digitoxigenin,Digitoxin,Hydroxylation,In Vitro Techniques,Male,Microsomes; Liver,NADP,Rats,Time Factors},
  pages = {1639--1641},
  pmid = {10}
}

@article{Hussey1976,
  title = {Editorial: {{Pneumococcal}} Appendicitis and Cecitis},
  volume = {236},
  issn = {0098-7484},
  shorttitle = {Editorial},
  language = {ENG},
  timestamp = {2016-10-24T11:18:29Z},
  number = {12},
  journal = {JAMA},
  author = {Hussey, H. H.},
  month = sep,
  year = {1976},
  keywords = {Abscess,Acute Disease,Adult,Appendicitis,Cecal Diseases,Child,Enteritis,Humans,Male,Pneumococcal Infections,Streptococcus pneumoniae,Suppuration},
  pages = {1388},
  pmid = {8653}
}

@article{Makar1975,
  title = {Formate Assay in Body Fluids: Application in Methanol Poisoning},
  volume = {13},
  issn = {0006-2944},
  shorttitle = {Formate Assay in Body Fluids},
  language = {ENG},
  timestamp = {2016-10-24T11:18:31Z},
  number = {2},
  journal = {Biochemical Medicine},
  author = {Makar, A. B. and McMartin, K. E. and Palese, M. and Tephly, T. R.},
  month = jun,
  year = {1975},
  keywords = {Aldehyde Oxidoreductases,Animals,Body Fluids,Carbon Dioxide,Formates,Haplorhini,Humans,Hydrogen-Ion Concentration,kinetics,Methanol,Methods,Pseudomonas},
  pages = {117--126},
  pmid = {1}
}

@article{Makar1975a,
  title = {Formate Assay in Body Fluids: Application in Methanol Poisoning},
  volume = {13},
  issn = {0006-2944},
  shorttitle = {Formate Assay in Body Fluids},
  language = {ENG},
  timestamp = {2016-10-24T11:18:33Z},
  number = {2},
  journal = {Biochemical Medicine},
  author = {Makar, A. B. and McMartin, K. E. and Palese, M. and Tephly, T. R.},
  month = jun,
  year = {1975},
  keywords = {Aldehyde Oxidoreductases,Animals,Body Fluids,Carbon Dioxide,Formates,Haplorhini,Humans,Hydrogen-Ion Concentration,kinetics,Methanol,Methods,Pseudomonas},
  pages = {117--126},
  pmid = {1}
}

@article{Sonnhof1975,
  title = {Inhibitory Postsynaptic Actions of Taurine, {{GABA}} and Other Amino Acids on Motoneurons of the Isolated Frog Spinal Cord},
  volume = {100},
  issn = {0006-8993},
  abstract = {The actions of glycine, GABA, alpha-alanine, beta-alanine and taurine were studied by intracellular recordings from lumbar motoneurons of the isolated spinal cord of the frog. All amino acids tested produced a reduction in the amplitude of postsynaptic potentials, a blockade of the antidromic action potential and an increase of membrane conductance. Furthermore, membrane polarizations occurred, which were always in the same direction as the IPSP. All these effects indicate a postsynaptic inhibitory action of these amino acids. When the relative strength of different amino acids was compared, taurine had the strongest inhibitory potency, followed by beta-alanine, alpha-alanine, GABA and glycine. Topically applied strychnine and picrotoxin induced different changes of post-synaptic potentials, indicating that distinct inhibitory systems might be influenced by these two convulsants. Interactions with amino acids showed that picrotoxin seletively diminished the postsymaptic actions of GABA, while strychnine reduced the effects of taurine, glycine, alpha- and beta-alanine. But differences in the susceptibility of these amino acid actions to strychnine could be detected: the action of taurine was more sensitively blocked by strychnine compared with glycine, alpha- and beta-alanine. With regard to these results the importance of taurine and GABA as transmitters of postsynaptic inhibition on motoneurons in the spinal cord of the frog is discussed.},
  language = {ENG},
  timestamp = {2016-10-24T11:18:35Z},
  number = {2},
  journal = {Brain Research},
  author = {Sonnhof, U. and Grafe, P. and Krumnikl, J. and Linder, M. and Schindler, L.},
  month = dec,
  year = {1975},
  keywords = {Alanine,Amino Acids,Animals,Anura,Depression; Chemical,Drug Interactions,Evoked Potentials,gamma-Aminobutyric Acid,Glycine,Membrane Potentials,Motor Neurons,Neural Inhibition,Neurotransmitter Agents,Picrotoxin,Rana esculenta,Spinal Cord,Spinal Nerve Roots,Stereoisomerism,Strychnine,Synaptic Membranes,Taurine},
  pages = {327--341},
  pmid = {128}
}

@article{zotero-null-208,
  timestamp = {2016-10-24T11:24:01Z}
}

@article{Makar1975b,
  title = {Formate Assay in Body Fluids: Application in Methanol Poisoning},
  volume = {13},
  issn = {0006-2944},
  shorttitle = {Formate Assay in Body Fluids},
  language = {ENG},
  timestamp = {2016-10-24T11:24:48Z},
  number = {2},
  journal = {Biochemical Medicine},
  author = {Makar, A. B. and McMartin, K. E. and Palese, M. and Tephly, T. R.},
  month = jun,
  year = {1975},
  keywords = {Aldehyde Oxidoreductases,Animals,Body Fluids,Carbon Dioxide,Formates,Haplorhini,Humans,Hydrogen-Ion Concentration,kinetics,Methanol,Methods,Pseudomonas},
  pages = {117--126},
  pmid = {1}
}

@article{Hussey1976a,
  title = {Editorial: {{Pneumococcal}} Appendicitis and Cecitis},
  volume = {236},
  issn = {0098-7484},
  shorttitle = {Editorial},
  language = {ENG},
  timestamp = {2016-10-24T11:24:50Z},
  number = {12},
  journal = {JAMA},
  author = {Hussey, H. H.},
  month = sep,
  year = {1976},
  keywords = {Abscess,Acute Disease,Adult,Appendicitis,Cecal Diseases,Child,Enteritis,Humans,Male,Pneumococcal Infections,Streptococcus pneumoniae,Suppuration},
  pages = {1388},
  pmid = {8653}
}

@article{Makar1975c,
  title = {Formate Assay in Body Fluids: Application in Methanol Poisoning},
  volume = {13},
  issn = {0006-2944},
  shorttitle = {Formate Assay in Body Fluids},
  language = {ENG},
  timestamp = {2016-10-24T11:24:52Z},
  number = {2},
  journal = {Biochemical Medicine},
  author = {Makar, A. B. and McMartin, K. E. and Palese, M. and Tephly, T. R.},
  month = jun,
  year = {1975},
  keywords = {Aldehyde Oxidoreductases,Animals,Body Fluids,Carbon Dioxide,Formates,Haplorhini,Humans,Hydrogen-Ion Concentration,kinetics,Methanol,Methods,Pseudomonas},
  pages = {117--126},
  pmid = {1}
}

@article{Schmoldt1975a,
  title = {Digitoxin Metabolism by Rat Liver Microsomes},
  volume = {24},
  issn = {0006-2952},
  language = {ENG},
  timestamp = {2016-10-24T11:24:54Z},
  number = {17},
  journal = {Biochemical Pharmacology},
  author = {Schmoldt, A. and Benthe, H. F. and Haberland, G.},
  month = sep,
  year = {1975},
  keywords = {Animals,Chromatography; Thin Layer,Digitoxigenin,Digitoxin,Hydroxylation,In Vitro Techniques,Male,Microsomes; Liver,NADP,Rats,Time Factors},
  pages = {1639--1641},
  pmid = {10}
}

@article{Sonnhof1975a,
  title = {Inhibitory Postsynaptic Actions of Taurine, {{GABA}} and Other Amino Acids on Motoneurons of the Isolated Frog Spinal Cord},
  volume = {100},
  issn = {0006-8993},
  abstract = {The actions of glycine, GABA, alpha-alanine, beta-alanine and taurine were studied by intracellular recordings from lumbar motoneurons of the isolated spinal cord of the frog. All amino acids tested produced a reduction in the amplitude of postsynaptic potentials, a blockade of the antidromic action potential and an increase of membrane conductance. Furthermore, membrane polarizations occurred, which were always in the same direction as the IPSP. All these effects indicate a postsynaptic inhibitory action of these amino acids. When the relative strength of different amino acids was compared, taurine had the strongest inhibitory potency, followed by beta-alanine, alpha-alanine, GABA and glycine. Topically applied strychnine and picrotoxin induced different changes of post-synaptic potentials, indicating that distinct inhibitory systems might be influenced by these two convulsants. Interactions with amino acids showed that picrotoxin seletively diminished the postsymaptic actions of GABA, while strychnine reduced the effects of taurine, glycine, alpha- and beta-alanine. But differences in the susceptibility of these amino acid actions to strychnine could be detected: the action of taurine was more sensitively blocked by strychnine compared with glycine, alpha- and beta-alanine. With regard to these results the importance of taurine and GABA as transmitters of postsynaptic inhibition on motoneurons in the spinal cord of the frog is discussed.},
  language = {ENG},
  timestamp = {2016-10-24T11:24:56Z},
  number = {2},
  journal = {Brain Research},
  author = {Sonnhof, U. and Grafe, P. and Krumnikl, J. and Linder, M. and Schindler, L.},
  month = dec,
  year = {1975},
  keywords = {Alanine,Amino Acids,Animals,Anura,Depression; Chemical,Drug Interactions,Evoked Potentials,gamma-Aminobutyric Acid,Glycine,Membrane Potentials,Motor Neurons,Neural Inhibition,Neurotransmitter Agents,Picrotoxin,Rana esculenta,Spinal Cord,Spinal Nerve Roots,Stereoisomerism,Strychnine,Synaptic Membranes,Taurine},
  pages = {327--341},
  pmid = {128}
}

@article{Makar1975d,
  title = {Formate Assay in Body Fluids: Application in Methanol Poisoning},
  volume = {13},
  issn = {0006-2944},
  shorttitle = {Formate Assay in Body Fluids},
  language = {ENG},
  timestamp = {2016-10-24T11:24:58Z},
  number = {2},
  journal = {Biochemical Medicine},
  author = {Makar, A. B. and McMartin, K. E. and Palese, M. and Tephly, T. R.},
  month = jun,
  year = {1975},
  keywords = {Aldehyde Oxidoreductases,Animals,Body Fluids,Carbon Dioxide,Formates,Haplorhini,Humans,Hydrogen-Ion Concentration,kinetics,Methanol,Methods,Pseudomonas},
  pages = {117--126},
  pmid = {1}
}

@article{Spinellis2005a,
  title = {If Your Version Control System Could Talk},
  timestamp = {2016-10-24T11:32:13Z},
  number = {September/October 2005},
  journal = {IEEE SOFTWARE},
  author = {Spinellis, Diomidis},
  year = {2005},
  pages = {108--109},
  file = {Spinellis - 2005 - If your version control system could talk.pdf:/home/martin/.mozilla/firefox/2czweqll.default/zotero/storage/URJQ8XH5/Spinellis - 2005 - If your version control system could talk.pdf:application/pdf}
}

@book{OSullivan2009,
  address = {Sebastopol},
  title = {Mercurial: The {{Definitive Guide}}.},
  isbn = {978-0-596-55547-4},
  shorttitle = {Mercurial},
  abstract = {Mercurial is the easiest system to learn when it comes to distributed revision control-ideal whether you're a lone programmer working on a small project, or part of huge team dealing with thousands of files. This definitive guide takes you step by step through ways to track, merge, and manage both open source and commercial software projects with Mercurial, using Windows, Mac OS X, Linux, Solaris, and other systems.},
  language = {English},
  timestamp = {2016-10-24T12:44:20Z},
  urldate = {2016-10-24},
  url = {http://public.eblib.com/choice/publicfullrecord.aspx?p=443427},
  publisher = {{O'Reilly Media, Inc.}},
  author = {O'Sullivan, Bryan},
  year = {2009},
  note = {OCLC: 609841351}
}

@article{Beard2009,
  title = {{{CellML}} Metadata Standards, Associated Tools and Repositories},
  volume = {367},
  copyright = {Copyright \textcopyright{} 2009 The Royal Society. This is an open-access article distributed under the terms of the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original work is properly cited.},
  issn = {1364-503X, 1471-2962},
  doi = {10.1098/rsta.2008.0310},
  abstract = {The development of standards for encoding mathematical models is an important component of model building and model sharing among scientists interested in understanding multi-scale physiological processes. CellML provides such a standard, particularly for models based on biophysical mechanisms, and a substantial number of models are now available in the CellML Model Repository. However, there is an urgent need to extend the current CellML metadata standard to provide biological and biophysical annotation of the models in order to facilitate model sharing, automated model reduction and connection to biological databases. This paper gives a broad overview of a number of new developments on CellML metadata and provides links to further methodological details available from the CellML website.},
  language = {en},
  timestamp = {2016-10-24T16:11:29Z},
  number = {1895},
  urldate = {2016-10-24},
  url = {http://rsta.royalsocietypublishing.org/content/367/1895/1845},
  journal = {Philosophical Transactions of the Royal Society of London A: Mathematical, Physical and Engineering Sciences},
  author = {Beard, Daniel A. and Britten, Randall and Cooling, Mike T. and Garny, Alan and Halstead, Matt D. B. and Hunter, Peter J. and Lawson, James and Lloyd, Catherine M. and Marsh, Justin and Miller, Andrew and Nickerson, David P. and Nielsen, Poul M. F. and Nomura, Taishin and Subramanium, Shankar and Wimalaratne, Sarala M. and Yu, Tommy},
  month = may,
  year = {2009},
  pages = {1845--1867},
  file = {Full Text PDF:/home/martin/.mozilla/firefox/2czweqll.default/zotero/storage/WCHSCZ25/Beard et al. - 2009 - CellML metadata standards, associated tools and re.pdf:application/pdf;Snapshot:/home/martin/.mozilla/firefox/2czweqll.default/zotero/storage/XENPAHJJ/1845.html:text/html},
  pmid = {19380315}
}

@article{Hucka2003,
  title = {The Systems Biology Markup Language ({{SBML}}): A Medium for Representation and Exchange of Biochemical Network Models},
  volume = {19},
  issn = {1367-4803, 1460-2059},
  shorttitle = {The Systems Biology Markup Language ({{SBML}})},
  doi = {10.1093/bioinformatics/btg015},
  abstract = {Motivation: Molecular biotechnology now makes it possible to build elaborate systems models, but the systems biology community needs information standards if models are to be shared, evaluated and developed cooperatively.
Results: We summarize the Systems Biology Markup Language (SBML) Level 1, a free, open, XML-based format for representing biochemical reaction networks. SBML is a software-independent language for describing models common to research in many areas of computational biology, including cell signaling pathways, metabolic pathways, gene regulation, and others.
Availability: The specification of SBML Level 1 is freely available from http://www.sbml.org/
Contact: sysbio-team\{at\}caltech.edu},
  language = {en},
  timestamp = {2016-10-24T16:12:40Z},
  number = {4},
  urldate = {2016-10-24},
  url = {http://bioinformatics.oxfordjournals.org/content/19/4/524},
  journal = {Bioinformatics},
  author = {Hucka, M. and Finney, A. and Sauro, H. M. and Bolouri, H. and Doyle, J. C. and Kitano, H. and Forum, and the rest of the SBML and Arkin, A. P. and Bornstein, B. J. and Bray, D. and Cornish-Bowden, A. and Cuellar, A. A. and Dronov, S. and Gilles, E. D. and Ginkel, M. and Gor, V. and Goryanin, I. I. and Hedley, W. J. and Hodgman, T. C. and Hofmeyr, J.-H. and Hunter, P. J. and Juty, N. S. and Kasberger, J. L. and Kremling, A. and Kummer, U. and Nov{\`e}re, N. Le and Loew, L. M. and Lucio, D. and Mendes, P. and Minch, E. and Mjolsness, E. D. and Nakayama, Y. and Nelson, M. R. and Nielsen, P. F. and Sakurada, T. and Schaff, J. C. and Shapiro, B. E. and Shimizu, T. S. and Spence, H. D. and Stelling, J. and Takahashi, K. and Tomita, M. and Wagner, J. and Wang, J.},
  month = jan,
  year = {2003},
  pages = {524--531},
  file = {Full Text PDF:/home/martin/.mozilla/firefox/2czweqll.default/zotero/storage/6WSAVUG7/Hucka et al. - 2003 - The systems biology markup language (SBML) a medi.pdf:application/pdf;Snapshot:/home/martin/.mozilla/firefox/2czweqll.default/zotero/storage/GMRH65MQ/524.html:text/html},
  pmid = {12611808}
}

@article{Miller2011,
  title = {Revision History Aware Repositories of Computational Models of Biological Systems},
  volume = {12},
  issn = {1471-2105},
  doi = {10.1186/1471-2105-12-22},
  abstract = {Building repositories of computational models of biological systems ensures that published models are available for both education and further research, and can provide a source of smaller, previously verified models to integrate into a larger model.},
  timestamp = {2016-10-24T16:13:54Z},
  urldate = {2016-10-24},
  url = {http://dx.doi.org/10.1186/1471-2105-12-22},
  journal = {BMC Bioinformatics},
  author = {Miller, Andrew K. and Yu, Tommy and Britten, Randall and Cooling, Mike T. and Lawson, James and Cowan, Dougal and Garny, Alan and Halstead, Matt DB and Hunter, Peter J. and Nickerson, David P. and Nunns, Geo and Wimalaratne, Sarala M. and F Nielsen, Poul M.},
  year = {2011},
  pages = {22},
  annote = {Pages 22 in PDF},
  file = {Full Text PDF:/home/martin/.mozilla/firefox/2czweqll.default/zotero/storage/2C48UTV4/Miller et al. - 2011 - Revision history aware repositories of computation.pdf:application/pdf;Snapshot:/home/martin/.mozilla/firefox/2czweqll.default/zotero/storage/WZ8ATP4V/1471-2105-12-22.html:text/html}
}

@book{Chacon2014,
  edition = {2nd ed. edition},
  title = {Pro {{Git}}},
  isbn = {978-1-4842-0077-3},
  abstract = {Pro Git (Second Edition) is your fully-updated guide to Git and its usage in the modern world. Git has come a long way since it was first developed by Linus Torvalds for Linux kernel development. It has taken the open source world by storm since its inception in 2005, and this book teaches you how to use it like a pro. Effective and well-implemented version control is a necessity for successful web projects, whether large or small. With this book you'll learn how to master the world of distributed version workflow, use the distributed features of Git to the full, and extend Git to meet your every need. Written by Git pros Scott Chacon and Ben Straub, Pro Git (Second Edition) builds on the hugely successful first edition, and is now fully updated for Git version 2.0, as well as including an indispensable chapter on GitHub. It's the best book for all your Git needs.What you'll learn\textbullet{} Effectively use Git, either as a programmer or a project leader\textbullet{} Become a fluent Git user\textbullet{} Master branching, using Git on the server, and on other systems\textbullet{} Integrate Git in your development workflow\textbullet{} Migrate programming projects from other SCMs to Git\textbullet{} Extend Git for your personal project needs\textbullet{} Effectively use GitHubWho this book is forThis book is for all open source developers: you are bound to encounter Git somewhere in the course of your working life. Proprietary software developers will appreciate Git's enormous scalability, since it is used for the Linux project, which comprises thousands of developers and testers.Table of Contents1. Getting Started2. Git Basics3. Git Branching4. Git on the Server5. Distributed Git6. GitHub7. Git Tools8. Customizing Git9. Git and Other Systems10. Git Internals},
  language = {English},
  timestamp = {2016-10-29T14:04:25Z},
  publisher = {{Apress}},
  author = {Chacon, Scott and Straub, Ben},
  month = nov,
  year = {2014},
  file = {Chacon and Straub - 2014 - Pro Git.pdf:/home/martin/.mozilla/firefox/2czweqll.default/zotero/storage/BMZUX7C2/Chacon and Straub - 2014 - Pro Git.pdf:application/pdf}
}

@misc{zotero-null-243,
  title = {New {{Tab}}},
  timestamp = {2016-11-06T19:07:03Z},
  urldate = {2016-11-06},
  url = {about:newtab},
  file = {New Tab:/home/martin/.mozilla/firefox/2czweqll.default/zotero/storage/HGG22BHJ/newtab.html:application/xhtml+xml}
}

@article{Cuellar2003,
  title = {An {{Overview}} of {{CellML}} 1.1, a {{Biological Model Description Language}}},
  volume = {79},
  issn = {0037-5497, 1741-3133},
  doi = {10.1177/0037549703040939},
  abstract = {CellML is an XML-based exchange format developed by the University of Auckland in collaboration with Physiome Sciences, Inc. CellML 1.1 has a component-based architecture allowing a modeller to build complex systems of models that expand and reuse previously published models. CellML Metadata is a format for encoding contextual information for a model. CellML 1.1 can be used in conjunction with CellML Metadata to provide a complete description of the structure and underlying mathematics of biological models. A repository of over 200 electrophysiological, mechanical, signal transduction, and metabolic pathway models is available at www.cellml.org.},
  language = {en},
  timestamp = {2016-11-06T19:15:47Z},
  number = {12},
  urldate = {2016-11-06},
  url = {http://sim.sagepub.com/content/79/12/740},
  journal = {SIMULATION},
  author = {Cuellar, Autumn A. and Lloyd, Catherine M. and Nielsen, Poul F. and Bullivant, David P. and Nickerson, David P. and Hunter, Peter J.},
  month = jan,
  year = {2003},
  keywords = {Biological model,markup language,mathematical model,XML},
  pages = {740--747},
  file = {Full Text PDF:/home/martin/.mozilla/firefox/2czweqll.default/zotero/storage/WKMBXWM5/Cuellar et al. - 2003 - An Overview of CellML 1.1, a Biological Model Desc.pdf:application/pdf;Snapshot:/home/martin/.mozilla/firefox/2czweqll.default/zotero/storage/7K72M3DE/740.html:text/html}
}

@misc{zotero-null-249,
  timestamp = {2016-11-09T13:01:26Z},
  urldate = {2016-11-09},
  url = {https://scholar.googleusercontent.com/scholar.bib?q=info:IzqN-uHMMqYJ:scholar.google.com/\&output=citation\&scisig=AAGBfm0AAAAAWCMgbbtlBKPvDhOX6TxLa5nd9WffikrT\&scisf=4\&ct=citation\&cd=-1\&hl=de},
  annote = {
@article\{bray1998extensible, title=\{Extensible markup language (XML)\}, author=\{Bray, Tim and Paoli, Jean and Sperberg-McQueen, C Michael and Maler, Eve and Yergeau, Fran\{$\backslash$c\{c\}\}ois\}, journal=\{World Wide Web Consortium Recommendation REC-xml-19980210. http://www. w3. org/TR/1998/REC-xml-19980210\}, volume=\{16\}, pages=\{16\}, year=\{1998\} \}
},
  file = {scholar.asc:/home/martin/.mozilla/firefox/2czweqll.default/zotero/storage/54TT975J/scholar.asc:text/plain}
}

@article{Bray1998,
  title = {Extensible Markup Language ({{XML}})},
  volume = {16},
  abstract = {The Extensible Markup Language (XML) is a subset of SGML that is completely described in this document.
Its goal is to enable generic SGML to be served, received, and processed on the Web in the way that is
now possible with HTML. XML has been designed for ease of implementation and for interoperability
with both SGML and HTML.},
  language = {English},
  timestamp = {2016-11-09T13:06:36Z},
  urldate = {2016-11-09},
  url = {http://www.w3.org/TR/1998/REC-xml-19980210},
  journal = {World Wide Web Consortium Recommendation},
  author = {Bray, Tim and Paoli, Jean and Sperberg-McQueen, C Micheal and Maler, Eve and Vergeau, Fran{\c c}ois and Cowan, John},
  year = {1998},
  pages = {16},
  file = {Bray et al. - 1998 - Extensible markup language (XML).pdf:/home/martin/.mozilla/firefox/2czweqll.default/zotero/storage/B4KCIVQP/Bray et al. - 1998 - Extensible markup language (XML).pdf:application/pdf}
}

@book{Lassila1998,
  title = {Resource {{Description Framework}} ({{RDF}}) {{Model}} and {{Syntax Specification}}},
  abstract = {This document is a revision of the public working draft dated 1998-08-19 incorporating suggestions received in review comments and further deliberations of the W3C RDF Model and Syntax Working Group. With the publication of this draft, the RDF Model and Syntax Specification enters "last call." The last call period will end on October 23, 1998. Comments on this specification may be sent to www-rdf-comments@w3.org. The archive of public comments is available at http://www.w3.org/Archives/Public/www-rdf-comments. Significant changes from the previous draft are highlighted in Appendix E. While we do not anticipate substantial changes, we still caution that further changes are possible. Therefore while we encourage active implementation to test this specification we also recommend that only software that can be easily field-upgraded be implemented to this specification at this time. This is a W3C Working Draft for review by W3C members and other interested parties. Publication as a working draft does not imply endorsement by the W3C membership. The RDF Model and Syntax  Working Group will not allow early implementation to constrain their ability to make changes to this specification prior to final release. This is a draft document and may be updated, replaced or obsoleted by other documents at any time. It is inappropriate to cite W3C Working Drafts as other than "work in progress". This work is part of the W3C Metadata Activity.},
  timestamp = {2016-11-09T14:52:02Z},
  author = {Lassila, Ora and Swick, Ralph R. and Wide, World and Consortium, Web},
  year = {1998},
  file = {Citeseer - Full Text PDF:/home/martin/.mozilla/firefox/2czweqll.default/zotero/storage/AZG54MUB/Lassila et al. - 1998 - Resource Description Framework (RDF) Model and Syn.pdf:application/pdf;Citeseer - Snapshot:/home/martin/.mozilla/firefox/2czweqll.default/zotero/storage/EK2TB8V3/summary.html:text/html}
}

@article{Carlisle2003,
  title = {Mathematical {{Markup Language}} ({{MathML}}) {{Version}} 2.0 ({{Second Edition}})},
  abstract = {This specification defines the Mathematical Markup Language, or MathML. MathML is an XML application for describing mathematical notation and capturing both its structure and content. The goal of MathML is to enable mathematics to be served, received, and processed on the World Wide Web, just as HTML has enabled this functionality for text.

This specification of the markup language MathML is intended primarily for a readership consisting of those who will be developing or implementing renderers or editors using it, or software that will communicate using MathML as a protocol for input or output. It is not a User's Guide but rather a reference document.

This document begins with background information on mathematical notation, the problems it poses, and the philosophy underlying the solutions MathML 2.0 proposes. MathML can be used to encode both mathematical notation and mathematical content. About thirty of the MathML tags describe abstract notational structures, while another about one hundred and fifty provide a way of unambiguously specifying the intended meaning of an expression. Additional chapters discuss how the MathML content and presentation elements interact, and how MathML renderers might be implemented and should interact with browsers. Finally, this document addresses the issue of MathML characters and their relation to fonts.

While MathML is human-readable, it is anticipated that, in all but the simplest cases, authors will use equation editors, conversion programs, and other specialized software tools to generate MathML. Several versions of such MathML tools already exist, and a number of others, both freely available software and commercial products, are under development.},
  timestamp = {2016-11-09T14:55:42Z},
  urldate = {2016-11-09},
  url = {https://www.w3.org/TR/MathML2/},
  journal = {World Wide Web Consortium Recommendation},
  author = {Carlisle, David and Ion, Patrick and Miner, Robert and Poppelier, Nico},
  month = oct,
  year = {2003},
  file = {Carlisle et al. - 2003 - Mathematical Markup Language (MathML) Version 2.0 .pdf:/home/martin/.mozilla/firefox/2czweqll.default/zotero/storage/MEX3KN56/Carlisle et al. - 2003 - Mathematical Markup Language (MathML) Version 2.0 .pdf:application/pdf;Mathematical Markup Language (MathML) Version 2.0 (Second Edition):/home/martin/.mozilla/firefox/2czweqll.default/zotero/storage/C3QWN4GP/MathML2.html:text/html}
}

@article{DeRose2010,
  title = {{{XML Linking Language}} ({{XLink}}) {{Version}} 1.1},
  abstract = {This specification defines the XML Linking Language (XLink) Version 1.1, which allows elements to be inserted into XML documents in order to create and describe links between resources. It uses XML syntax to create structures that can describe links similar to the simple unidirectional hyperlinks of today's HTML, as well as more sophisticated links.},
  timestamp = {2016-11-09T15:04:36Z},
  urldate = {2016-11-09},
  url = {https://www.w3.org/TR/xlink11/},
  journal = {World Wide Web Consortium Recommendation},
  author = {DeRose, Steve and Maler, Eve and Orchard, David and Walsh, Norman},
  month = may,
  year = {2010},
  file = {XML Linking Language (XLink) Version 1.1:/home/martin/.mozilla/firefox/2czweqll.default/zotero/storage/8FHM9PPK/xlink11.html:text/html}
}

@article{Drager2014,
  title = {Improving Collaboration by Standardization Efforts in Systems Biology},
  volume = {2},
  doi = {10.3389/fbioe.2014.00061},
  abstract = {Collaborative genome-scale reconstruction endeavors of metabolic networks would not be possible without a common, standardized formal representation of these systems. The ability to precisely define biological building blocks together with their dynamic behavior has even been considered a prerequisite for upcoming synthetic biology approaches. Driven by the requirements of such ambitious research goals, standardization itself has become an active field of research on nearly all levels of granularity in biology. In addition to the originally envisaged exchange of computational models and tool interoperability, new standards have been suggested for an unambiguous graphical display of biological phenomena, to annotate, archive, as well as to rank models, and to describe execution and the outcomes of simulation experiments. The spectrum now even covers the interaction of entire neurons in the brain, three-dimensional motions, and the description of pharmacometric studies. Thereby, the mathematical description of systems and approaches for their (repeated) simulation are clearly separated from each other and also from their graphical representation. Minimum information definitions constitute guidelines and common operation protocols in order to ensure reproducibility of findings and a unified knowledge representation. Central database infrastructures have been established that provide the scientific community with persistent links from model annotations to online resources. A rich variety of open-source software tools thrives for all data formats, often supporting a multitude of programing languages. Regular meetings and workshops of developers and users lead to continuous improvement and ongoing development of these standardization efforts. This article gives a brief overview about the current state of the growing number of operation protocols, mark-up languages, graphical descriptions, and fundamental software support with relevance to systems biology.},
  language = {ENG},
  timestamp = {2016-11-09T17:11:02Z},
  journal = {Frontiers in Bioengineering and Biotechnology},
  author = {Dr{\"a}ger, Andreas and Palsson, Bernhard \O{}},
  year = {2014},
  keywords = {model databases,model formats,modeling guidelines,network visualization,Ontologies,software support},
  pages = {61},
  file = {Dräger and Palsson - 2014 - Improving collaboration by standardization efforts.pdf:/home/martin/.mozilla/firefox/2czweqll.default/zotero/storage/8FPTAU6M/Dräger and Palsson - 2014 - Improving collaboration by standardization efforts.pdf:application/pdf},
  pmid = {25538939},
  pmcid = {PMC4259112}
}

@techreport{Scharm2014a,
  title = {The {{CombineArchiveWeb}} Application \textendash{} {{A}} Web Based Tool to Handle Files Associated with Modelling Results},
  abstract = {Sharing in silico experiments is essential for the advance of research in computational biology. Consequently, the COMBINE archive was designed as a digital container format. It eases the management of files related to a modelling result, fosters collaboration, and ultimately enables the exchange of reproducible simulation studies. However, manual handling of COMBINE archives is tedious and error prone. We therefore developed the CombineArchiveWeb application to support scientists in promoting and publishing their research by means of creating, exploring, modifying, and sharing archives. All files are equipped with meta data and can be distributed over the Web through shareable workspaces.},
  language = {en},
  timestamp = {2016-11-09T19:34:34Z},
  number = {e639v1},
  urldate = {2016-11-09},
  url = {https://peerj.com/preprints/639v1},
  institution = {PeerJ PrePrints},
  author = {Scharm, Martin and Wendland, Florian and Peters, Martin and Wolfien, Markus and Theile, Tom and Waltemath, Dagmar},
  month = nov,
  year = {2014},
  file = {Full Text PDF:/home/martin/.mozilla/firefox/2czweqll.default/zotero/storage/49M946H3/Scharm et al. - 2014 - The CombineArchiveWeb application – A web based to.pdf:application/pdf;Snapshot:/home/martin/.mozilla/firefox/2czweqll.default/zotero/storage/BD3U9CAA/639v1.html:text/html}
}

@incollection{Shearer2008,
  title = {{{HermiT}}: {{A Highly}}-{{Efficient OWL Reasoner}}},
  volume = {432},
  abstract = {HermiT is a new OWL reasoner based on a novel ``hyper-
tableau'' calculus. The new calculus addresses performance problems due
to nondeterminism and model size\textemdash{}the primary sources of complexity
in state-of-the-art OWL reasoners. The latter is particularly important
in practice, and it is achieved in HermiT with an improved blocking
strategy and and an optimization that tries to reuse existing individuals
rather than generating new ones. HermiT also incorporates a number of
other novel optimizations, such as a more efficient approach to handling
nominals, and various techniques for optimizing ontology classification.
Our tests show that HermiT is usually much faster than other reasoners
when classifying complex ontologies, and it is already able to classify a
number of ontologies which no other reasoner has been able to handle.},
  timestamp = {2016-11-11T20:57:52Z},
  booktitle = {{{OWLED}}},
  author = {Shearer, Rob and Motik, Boris and Horrocks, Ian},
  year = {2008},
  pages = {91},
  file = {smh08HermiT.pdf:/home/martin/.mozilla/firefox/2czweqll.default/zotero/storage/J7V8VA9E/smh08HermiT.pdf:application/pdf}
}

@comment{jabref-meta: groupsversion:3;}
@comment{jabref-meta: groupstree:
0 AllEntriesGroup:;
1 ExplicitGroup:ba-thesis\;0\;Scharm2016\;Mesirov2010\;Ebert1994\;Oliv
ier2004\;Scharm2015a\;Scharm2014\;Waltemath2011\;Goble2010\;Hucka2015\
;Scharm2015\;Stanford2015\;DeVirgilio2014\;Waltemath2013\;Kohn2008\;Ch
en1976\;Henkel2014\;Waltemath2011a\;Angles2008\;Cobena2002\;McEntyre20
15\;Hunt1976\;Siriwaradhana2014\;Henkel2015\;Schmidt2000\;Ronnau2005\;
Chawathe1996\;Peng2011\;Gentleman2005\;Wang2003\;McCullough2008\;Genna
ri2011\;Smith2007\;Ashburner2000\;Prinz2011\;Bergmann2014\;Bergmann201
4a\;COMBINE\;Saake2010\;Lysenko2016\;Tudorica2011\;Teorey1986\;Courtot
2011\;Finkelstein2004\;Henkel2010\;Henkel2012\;Li2010\;Yu2011\;Bechhof
er2009\;Berners-Lee2001\;Berners-Lee2001a\;Shadbolt2006\;Bechhofer2004
\;Robinson2013\;Collins-Sussman2004\;Spinellis2005\;Hussey1976\;Hussey
1976a\;Spinellis2005a\;OSullivan2009\;Beard2009\;Hucka2003\;Miller2011
\;Chacon2014\;Cuellar2003\;Bray1998\;Lassila1998\;Carlisle2003\;DeRose
2010\;Drager2014\;Scharm2014a\;Shearer2008\;;
1 ExplicitGroup:zotero-stuff\;0\;Chemiker\;zotero-null-25\;;
}

