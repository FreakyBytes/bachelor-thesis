% !TeX spellcheck = en_US
%\section{Motivation}
"Scientific publications have at least two goals: (i) to announce a result and (ii) to convince readers that the result is correct" \citep{Mesirov2010}.
This paradigm has ruled the world of scientific publications since its beginnings, but the last two decades proved to provide challenges for it. With the improvement and further development of computational tools, more advanced analysis and complex computation methods are available to a broader audience by software packages and tools. Now, people who have no or very little background in Mathematics or Computer Science face the challenge to comply with the second point mentioned by \citeauthor{Mesirov2010}. Also with increasing complexity it becomes challenging to describe the complicated workflow within the word limitation of a normal publication.
For instance, biologists can now easily acquire large DNA or RNA sequencing datasets, which  are too large to analyze manually.
This data first needs to be preprocessed in order to extract meaningful results. %Those data needs to be sanitized, converted and condensed, to make sense out of it.
Very often researchers without a computer science background do not accurately describe their methodology, hence resulting findings can not accurately be reproduced \citep{Peng2011}.
%Resulting publications often only pay little attention to the computational processes involved or even to the used algorithms \citep{Peng2011}.
\todo{Since the work cannot be reproduced, it is not possible to build upon the findings and therefore can be used prove the hypothesis.}
%But why is it of such a tremendous importance to know exactly every step leading to a result? Basically this is the foundation of scientific publications and peer review. Without in-depth knowledge of the methods, the environment and the workflow it is impossible to reproduce the experiment or observation and therefore it is impossible to prove or disprove the correctness of the assumption. 
%This inability may lead into blind trust in publications, making room for wrong or made-up scientific findings.
Especially valuable are these information, when dealing with studies, which may not be easily independently redone, because of resource, time or financial constraints \citep{Peng2011}.
\todo{Provide the example from the Peng? guy.} \todo{emphasis one of the constraints in the expample -> time}
Therefore ways or methods of reproducibility need to be \todo{add qualifier} addressed. \citeauthor{Mesirov2010} suggests researchers to make use of a Reproducible Research Environment, providing a set of tools "with the ability to automatically track the provenance of data, analyses, and results and to package them".

Since \sysbio is an interdisciplinary field that heavily relies on people with different academic backgrounds, it is therefore especially important to ensure the clear reproducibility and exchangebility of data.
Models are a condensed way to represent knowledge and data and are essential to \sysbio.
Due to the importance of models in \sysbio, it is imperative that they are reproducible and built using standard formats \citep{Drager2014}.
It is of great importance to use standard formats because tools used to create the original model may no longer be available or supported \citep{Peng2011}.
\todo{That is, when a model is encoded in standard formats, the possibility of at least one tool able to decode this format in future is higher.}
Furthermore, standardization and reproducibility are needed in order expand on and share existing findings.
To this extend the \combine initiative has been founded to "coordinate the development of the various community standards and formats for computational models" \citep{COMBINE}.
Even though a standard to describe biological networks was successful, it was not sufficient in terms of the goal to ensure reproducibility. Therefore, \citeauthor{Waltemath2011a} developed \sedml \citep{Waltemath2011a} to share simulation experiment setups automating the workflow of creating, sanitizing, converting, condensing, and plotting data.

In addition to \sedml, the \ca was introduced by \citet{Bergmann2014a} such as to share relevant information and data regarding reproduction. This standard is useful and important for sharing additional information \citep{Bergmann2014a}. % such as basic provenance information.
Despite the benefits of using the \ca, certain problems have arisen. For instance, a \ca is a snapshot of a complex development process. It can only ship one specific version and no references to older or newer versions are available. This is indeed desired when reproducing specific findings from a model used in a publication, but however hinders the incorporation of newer versions of models or simulation descriptions to the already existing \todo{part}.

The lack of the references to older or newer versions creates a lack of transparency, since "users are often not only interested in the current value of data but also in changes" \citep{Cobena2002}. Furthermore there is currently no available model repository that is able to query and compare multiple model versions in a simple manner.
The main goal of this thesis is therefore to investigate a concept to store biological models in such a way that multiple versions can be accessed, queried, and compared. I furthermore introduced semantical annotations of changes between model versions, by doing so I improved the ability to query for a version of a model by specific criteria. Consequently it will also improve the user experience for systems biologists seeking to build onto existing models, as the evolution of models plays an important role for them \citep{Scharm2015}.

\begin{comment}

\begin{itemize}
\item Why is Reproducibility important (in life science/Bioinformatics)
	\subitem what is a problem?
	\subitem why is it important?
	\subitem specific points regarding Systems Bio
	\subitem refs to reproducible science
	
	\subitem "Scientific publications have at least two goals: (i) to announce a result and (ii) to convince readers that the result is correct. Mathematics papers are expected to contain a proof complete enough to allow knowledgeable readers to fill in any details. Papers in experimental science should describe the results and provide a clear enough protocol to allow successful repetition and extension." \citep{Mesirov2010}
	\subitem "More recently, scientists who are not themselves computational experts are conducting data analysis with a wide range of modular software tools and packages. Users may often combine these tools in unusual or novel ways. In biology, scientists are now routinely able to acquire and explore data sets far beyond the scope of manual analysis, including billions of DNA bases, millions of genotypes, and hundreds of thousands of RNA measurements. Similar issues may arise in other fields, such as astronomy, seismology, and meteorology. While propelling enormous progress, this increasing and sometimes “indirect” use of computation poses new challenges for scientific publication and replication. Large data sets are often analyzed many times, with modifications to the methods and parameters, and sometimes even updates of the data, until the final results are produced. The resulting publication often gives only scant attention to the computational details. Some have suggested these papers are “merely the advertisement of scholarship whereas the computer programs, input data, parameter values, etc. embody the scholarship itself ” (2). However, the actual code or software “mashup” that gave rise to the final analysis may be lost or unrecoverable." \citep{Mesirov2010}
	\subitem "The first element is a Reproducible Research Environment (RRE) for doing the computational work. An RRE provides computational tools together with the ability to automatically track the provenance of data, analyses, and results and to package them (or pointers to persistent versions of them) for redistribution." \citep{Mesirov2010}
\item Reproducibility
	\subitem \sedml scripts fails, when model changes
	\subitem cf. (Casadevall and Fang, 2010; Gentleman, 2005; Laine et al., 2007; Mesirov, 2010; Peng, 2011; Sandve et al., 2013; Waltemath et al., 2011, 2013b) \\ refs shameless stolen from bives paper discussion section
	\subitem " Researchers across a range of computational science disciplines have been calling for reproducibility, or reproducible research, as an attainable minimum standard for assessing the value of scientific claims, particularly when full independent replication of a study is not feasible (4–8)." \citep{Peng2011}
	\subitem "A critical barrier to reproducibility in many cases is that the computer code is no longer available. Interactive software systems often used for exploratory data analysis typically do not keep track of users’ actions in any concrete form. Even if researchers use software that is run by written code, often multiple packages are used, and the code that combines the different results together is not saved (10). Addressing this problem will require either changing the behavior of the software systems themselves or getting researchers to use other software systems that are more amenable to reproducibility." \citep{Peng2011}
	\subitem "[...] reproducibility is critical to tracking down the “bugs” of computational science. In cases with interesting findings, reproducibility can 	greatly facilitate building on those findings (12)." \citep{Peng2011}
	

\item Transparency
	\subitem "Tracking the evolution of a model, that is providing information about changes in the model and its encoding, plays an important role in supporting the user " \citep{Scharm2015}
	\subitem "Users are often not only interested in the current value of data but also in changes." \citep{Cobena2002}
	\subitem "The primary purpose of an archive is not to ensure replicability (King 1995, 494) but to enhance extensibility (which presumes replicability). Thus, an archive should make it easier for one researcher to build on the work of another [...]" \citep{McCullough2008}
	\subitem " For this reason, ‘data only’ archives are not conducive to replication; only data+code archives can facilitate replication. Even when data are proprietary, the code should still be made available, so that other researchers can apply the same method to new data or to check the accuracy of the code. See our recommendation 8 in the appendix." \citep{McCullough2008}
	
\item Tracking differences (Provenance)
	\subitem what has changed
	\subitem who has changed it
	\subitem oxford2012 + first bives paper

\item "distribution of models through these repositories accelerates collaborative research and encourages model reuse" \citep{Scharm2015}

\item Doing analysis of the evolution of a biological model
\item provide a comprehensive repository of biological models and their history
\item discover similarities and differences in the development of model through Ontology crosslinking
\item Motivation out of koehn2008 \citep{Kohn2008}
\end{itemize}

\todo{last paragraph of motivation is goals section, summarizing proposed solution}
\todo{research gap ausarbeiten}
\todo{look into MOST for stats regarding model versions}

\section{Objectives}
\begin{itemize}
\item develop a concept to support different versions in model databases
	\subitem \todo{mention masymos directly?}
	\subitem \todo{arg. structure bives->masymos//masymos->bives//generische mdb->version concept->bives->goal}
\item semantically connect the versions
	\subitem relation between versions? + comodi terms
	\subitem ref to semantic web
	\subitem reason -> allow evaluation and analysis
\item store differences to allow for efficient analysis
\item \todo{talk about possible results}
\end{itemize}
\end{comment}