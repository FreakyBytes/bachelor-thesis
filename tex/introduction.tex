% !TeX spellcheck = en_US
\section{Motivation}
"Scientific publications have at least two goals: (i) to announce a result and (ii) to convince readers that the result is correct" \cite{Mesirov2010}.
This paradigm has ruled the world of scientific publications since its beginnings, but the last two decades proved to provide challenges for it. With the improvement and further development of computational tools, more advanced analysis and complex computation gets available to a broader audience by software packages and tools. Now people who have no or very little background in Mathematics or Computer Science face the challenge to comply with the second point, mentioned by Mesirov. Also with increasing complexity it gets challenging to describe the complicated workflow within the word limitation of a normal publication.
For instance biologists are now easily able to acquire large datasets form DNA or RNA sequencing, which are way to large for manual analyses. Those data needs to be sanitized, converted and condensed, to make sense out of it. Resulting publications often only pay little attention to the computational processes involved or even to the used algorithms \cite{Peng2011}.
But why is it of such a tremendous importance to know exactly every step leading to a result? Basically this is the foundation of scientific publications and peer review. Without in-depth knowledge of the methods, the environment and the workflow it is impossible to reproduce the experiment or observation and therefore it is impossible to prove or disprove the correctness the assumption. This inability may lead into blind trust in publications, making room for wrong or made-up scientific findings.
Especially valuable are these information, when dealing with studies, which may not be easily independently redone, because of resource, time or financial constraints \cite{Peng2011}.
So, how can the challenge of improving reproducibility be tackled? Mesirov \cite{Mesirov2010} suggests the introduction of a "Reproducible Research Environment", providing a set of tools "with the ability to automatically track the provenance of data, analyses, and results and to package them".
The problem would be to develop and introduce this environment into the scientific community -- and even then, it would merely improve the situation for future publications.

What does this mean for \sysbio? \todo{State importance of models in sysbio}Models published in the scope of this field may or may not be available in standard formats. The tools used to create them, may or may not be openly available, or the they may or may not be development anymore \cite{Peng2011}.
In a field, which relies heavily on expanding on existing findings, these issues are having a huge impact on how people work.
This fact was acknowledged by a community of Systems Biologists, who wanted to improve the situation of sharing and distributing biological models, hence the \combine initiative was founded, "to coordinate the development of the various community standards and formats for computational models" \cite{COMBINE}.
However, a standard to describe biological networks was a huge progress, but not sufficient in terms of goal to ensure reproducibility. Therefore Dagmar Waltemath developed \sedml \cite{Waltemath2011a}, to share simulation experiment setups -- modeling the prior mentioned workflow of creating, sanitizing, converting and condensing/plotting data.

Eventually another standard, the \ca was introduced \cite{Bergmann2014a}, to share all relevant information and data for reproduction. This standard is useful and important for sharing additional information along with a paper, but it is merely just a snapshot of a process, leading to both benefits and problems: First it is important to freeze the setup, so it reproduces exactly the described behavior, since linking to the always newest version of the model will break the simulation description. On the other hand, however, the model and setup do not receive any updates or adjustments, which might lead to better insights. Further, the actual development, which induced the resulting model, is not reflected -- besides basic provenance information.
\todo{incorporate most stats}

Lacking of these features, the current situation fails tremendously on transparency, since "users are often not only interested in the current value of data but also in changes" \cite{Cobena2002}.
The objective of this thesis is therefore to investigate into a concept to store systems biology models in a way, that multiple versions can accessed, queried, and compared. Further, semantical annotations of changes between these versions shall be introduced. These additional relations are meant to improve the ability to query for a version of a model by specific criteria and consequently improving the user experience for biologists seeking to build onto existing models, as the evolution of them is plays an important role for them \cite{Scharm2015}.
\todo{ref to semantic web?}
At the time of writing, there is currently no model repository available incorporating these features. Certainly it is not goal of this work to create a new repository, but to show a concept and provide a prototypical implementation of it.

\begin{comment}

\begin{itemize}
\item Why is Reproducibility important (in life science/Bioinformatics)
	\subitem what is a problem?
	\subitem why is it important?
	\subitem specific points regarding Systems Bio
	\subitem refs to reproducible science
	
	\subitem "Scientific publications have at least two goals: (i) to announce a result and (ii) to convince readers that the result is correct. Mathematics papers are expected to contain a proof complete enough to allow knowledgeable readers to fill in any details. Papers in experimental science should describe the results and provide a clear enough protocol to allow successful repetition and extension." \cite{Mesirov2010}
	\subitem "More recently, scientists who are not themselves computational experts are conducting data analysis with a wide range of modular software tools and packages. Users may often combine these tools in unusual or novel ways. In biology, scientists are now routinely able to acquire and explore data sets far beyond the scope of manual analysis, including billions of DNA bases, millions of genotypes, and hundreds of thousands of RNA measurements. Similar issues may arise in other fields, such as astronomy, seismology, and meteorology. While propelling enormous progress, this increasing and sometimes “indirect” use of computation poses new challenges for scientific publication and replication. Large data sets are often analyzed many times, with modifications to the methods and parameters, and sometimes even updates of the data, until the final results are produced. The resulting publication often gives only scant attention to the computational details. Some have suggested these papers are “merely the advertisement of scholarship whereas the computer programs, input data, parameter values, etc. embody the scholarship itself ” (2). However, the actual code or software “mashup” that gave rise to the final analysis may be lost or unrecoverable." \cite{Mesirov2010}
	\subitem "The first element is a Reproducible Research Environment (RRE) for doing the computational work. An RRE provides computational tools together with the ability to automatically track the provenance of data, analyses, and results and to package them (or pointers to persistent versions of them) for redistribution." \cite{Mesirov2010}
\item Reproducibility
	\subitem \sedml scripts fails, when model changes
	\subitem cf. (Casadevall and Fang, 2010; Gentleman, 2005; Laine et al., 2007; Mesirov, 2010; Peng, 2011; Sandve et al., 2013; Waltemath et al., 2011, 2013b) \\ refs shameless stolen from bives paper discussion section
	\subitem " Researchers across a range of computational science disciplines have been calling for reproducibility, or reproducible research, as an attainable minimum standard for assessing the value of scientific claims, particularly when full independent replication of a study is not feasible (4–8)." \cite{Peng2011}
	\subitem "A critical barrier to reproducibility in many cases is that the computer code is no longer available. Interactive software systems often used for exploratory data analysis typically do not keep track of users’ actions in any concrete form. Even if researchers use software that is run by written code, often multiple packages are used, and the code that combines the different results together is not saved (10). Addressing this problem will require either changing the behavior of the software systems themselves or getting researchers to use other software systems that are more amenable to reproducibility." \cite{Peng2011}
	\subitem "[...] reproducibility is critical to tracking down the “bugs” of computational science. In cases with interesting findings, reproducibility can 	greatly facilitate building on those findings (12)." \cite{Peng2011}
	

\item Transparency
	\subitem "Tracking the evolution of a model, that is providing information about changes in the model and its encoding, plays an important role in supporting the user " \cite{Scharm2015}
	\subitem "Users are often not only interested in the current value of data but also in changes." \cite{Cobena2002}
	\subitem "The primary purpose of an archive is not to ensure replicability (King 1995, 494) but to enhance extensibility (which presumes replicability). Thus, an archive should make it easier for one researcher to build on the work of another [...]" \cite{McCullough2008}
	\subitem " For this reason, ‘data only’ archives are not conducive to replication; only data+code archives can facilitate replication. Even when data are proprietary, the code should still be made available, so that other researchers can apply the same method to new data or to check the accuracy of the code. See our recommendation 8 in the appendix." \cite{McCullough2008}
	
\item Tracking differences (Provenance)
	\subitem what has changed
	\subitem who has changed it
	\subitem oxford2012 + first bives paper

\item "distribution of models through these repositories accelerates collaborative research and encourages model reuse" \cite{Scharm2015}

\item Doing analysis of the evolution of a biological model
\item provide a comprehensive repository of biological models and their history
\item discover similarities and differences in the development of model through Ontology crosslinking
\item Motivation out of koehn2008 \cite{Kohn2008}
\end{itemize}

\todo{last paragraph of motivation is goals section, summarizing proposed solution}
\todo{research gap ausarbeiten}
\todo{look into MOST for stats regarding model versions}

\section{Objectives}
\begin{itemize}
\item develop a concept to support different versions in model databases
	\subitem \todo{mention masymos directly?}
	\subitem \todo{arg. structure bives->masymos//masymos->bives//generische mdb->version concept->bives->goal}
\item semantically connect the versions
	\subitem relation between versions? + comodi terms
	\subitem ref to semantic web
	\subitem reason -> allow evaluation and analysis
\item store differences to allow for efficient analysis
\item \todo{talk about possible results}
\end{itemize}
\end{comment}